{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assembly_Input_Model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1I9Gf89uSRQSNCD5DRpx0uOGLIdW4Pzv7","authorship_tag":"ABX9TyOBhl7bEF8GACkF3cIfhVEq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"tFXphBJJvG8g"},"source":["# Vector Input Model"]},{"cell_type":"markdown","metadata":{"id":"u61hBZ9EwNFa"},"source":["### Introduction\n","This model is based on the paper fron Jian et al. 2019 **[1]**. It uses a word vector representation of the malware as input and a CNN network for classification.\n","\n","In the paper, the model is trained an tested on the Microsoft BIG 2015 **[2]** dataset and achives a accuracy of 99.49%.\n","\n","In this inplementaion, that model has been trained on the Microsoft BIG 2015 dataset (2018 revision).\n","\n","The original paper does not directly mention model paramters such as filter size, but refers to a previous paper by Kim 2014 **[3]**. These paramters have therefore been extraced from this paper.\n","\n","### Model Alterations\n","1. As the original model results suffered from a leaky dataset, the originally presented model did not perform well on a non leaky dataset (~65% ± 5%) in this recreation. For this reason, the model was altered.\n","  - Instead of using a Channel Transformer as described in the original paper, a convolution layer was used. The kernel was then set to 4, which corresponds to the logic of assembly language.\n","2. While training the Ensemble model, it is required to disable eager execution during parts of the training process. Unfortunately BatchNormalisation does currently nonot support disabled eager execution (https://github.com/tensorflow/tensorflow/issues/35107)\n","  - Trying to sovle this issue by removing the BatchNormalisation Layer, and increasing the similarity to Kim 2014 **[3]** didn’t work.\n","  - Using a LayerNormalisation layer didn’t work either.\n","\n","### Results\n","The best results from this model and the comparion to the original paper results can be seen in the table.\n","\n","|Metric|Repilicated Model<br>(Upsampled Dataset)|Repilicated Model<br>(Leaky Dataset)|Original Model<br>(Leaky Dataset)|\n","|---|---|---|---|\n","|Accuracy|90.5%||99.49%|\n","|Precision|92%||99.51%|\n","|Recall|89.4%||99.51%|\n","\n","### Bibliography\n","**[1]** Y. Jiang, S. Li, Y. Wu, and F. Zou, ‘A Novel Image-Based Malware Classification Model Using Deep Learning’, in Neural Information Processing, vol. 11954, T. Gedeon, K. W. Wong, and M. Lee, Eds. Cham: Springer International Pub, 2019, pp. 150–161. doi: 10.1007/978-3-030-36711-4_14. <br>\n","**[2]** R. Ronen, M. Radu, C. Feuerstein, E. Yom-Tov, and M. Ahmadi, ‘Microsoft Malware Classification Challenge’. arXiv, Feb. 22, 2018. Accessed: May 26, 2022. [Online]. Available: http://arxiv.org/abs/1802.10135\n","<br>\n","**[3]** Y. Kim, ‘Convolutional Neural Networks for Sentence Classification’, in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Doha, Qatar, Oct. 2014, pp. 1746–1751. doi: 10.3115/v1/D14-1181.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"s7u65w09yPHY"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yk-D6FrxySDH"},"outputs":[],"source":["#@title Set hyperparameters:\n","\n","#@markdown The orignal paper does not mention how many epochs have been used for training. In this implementation it was found that [...] epochs lead to the best results \n","EPOCHS = 100 #@param {type:\"slider\", min:0, max:1000, step:10}\n","\n","#@markdown The orignal paper not mention the  learning rate used. In this implementation it was found that a learning rate of [...] lead to the best results\n","LEARNING_RATE =  0.0001#@param {type:\"number\"}\n","\n","#@markdown The orignal paper does not mention the Batch_size used. In this implementation it was found that a batch size of [...] lead to the best results\n","BATCH_SIZE = 40 #@param {type:\"slider\", min:1, max:100, step:1}\n","\n","#@markdown The orignal paper find that K 1 results in the best results. In this implementation it was found that a K of [...] lead to the best results\n","K = 5 #@param {type:\"slider\", min:1, max: 8, step:1}\n","\n","#@markdown The orignal paper set the max opcode size to 64, but does not experiment with different lenghts. In this implementation it was found that a K of [...] lead to the best results\n","MAX_OPCODE_LENGHT = 64 #@param {type:\"slider\", min:32, max: 256, step:32}\n","\n","#@markdown The paper does not clarifiy which dropout has been used after the final maxpooling. In this implementation, it has been found that [...] leads to the best resutls.\n","DROPOUT = 0.3 #@param {type:\"slider\", min:0, max:1, step:0.1}\n","\n","#@markdown Within the original paper, this parameter is called m as defined as 3200.\n","NUMBER_OF_INSTRUCTIONS = 3200 #@param {type:\"slider\", min:0, max:6400, step:200}\n","\n","#@markdown Whithin the paper, the dataset has been augumented. One can train the model with the augmented dataset or the pure dataset.\n","DATASET = \"Upsampled\" #@param [\"raw\", \"YongImage\",\"Upsampled\"]"]},{"cell_type":"code","source":["!pip install -q mlflow\n","!pip install -q folium==0.2.1\n","!pip install -q botocore\n","!pip install -q boto3\n","!pip install -q urllib3==1.25.9\n","\n","from keras.backend import dtype\n","from tensorflow.keras.utils import Sequence\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from keras.utils.vis_utils import plot_model\n","from keras.models import Model\n","from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization, Activation, Lambda\n","from keras.layers.convolutional import Conv1D, Conv2D, MaxPooling2D\n","from keras.layers.merge import concatenate\n","from keras.activations import tanh\n","from tensorflow.keras.optimizers import Adam\n","\n","import mlflow.tensorflow\n","import scipy.interpolate as interp\n","from os import environ\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.metrics import confusion_matrix\n","from keras.utils.vis_utils import plot_model\n","from keras.callbacks import Callback\n","\n","import numpy as np\n","import pandas as pd\n","from os import path\n","from os import makedirs\n","import re\n","from pyparsing import Word, hexnums, WordEnd, Optional, alphas, alphanums, printables, ParseException\n","\n","# Params for MLflow\n","MLFLOW_TRACKING_URI = 'https://c720-161-23-164-160.ngrok.io'\n","MLFLOW_S3_ENDPOINT_URL = 'https://2d2d-161-23-164-160.ngrok.io'\n","AWS_ACCESS_KEY_ID = \"minio\"\n","AWS_SECRET_ACCESS_KEY = \"SN2FbaVcHCBAqr\"\n","MLFLOW_TRACKING_USERNAME = 'admin'\n","MLFLOW_TRACKING_PASSWORD = 'DPBgs7Z8XQcNAp'\n","\n","Model_Name = 'MalVecNet'"],"metadata":{"id":"9zzFiisHqHpY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PciYW2oYvZME"},"source":["## Data Loading and Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7fe96ExvuDg"},"outputs":[],"source":["PROCESS_VERSION = 3\n","\n","if not path.exists(f'/content/dataset/{PROCESS_VERSION}/'):\n","  makedirs(f'/content/dataset/{PROCESS_VERSION}/')\n","%cp -R -n /content/drive/MyDrive/QMUL/Dissertation/dataset/processed/vector/{PROCESS_VERSION}/. /content/dataset/{PROCESS_VERSION}/\n","\n","\n","y_train_data = np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/y_train.npy')\n","df = pd.DataFrame(np.argmax(y_train_data,axis=1), columns=['lables'])\n","F1, F2, F3, F4, F5, F6, F7, F8, F9 = [(1/len(x)) for _, x in df.groupby(df['lables'])]\n","class_weight = {0:F1, 1:F2, 2: F3, 3:F4, 4:F5, 5:F6, 6:F7, 7:F8, 8:F9}\n","train_len = len(y_train_data)\n","test_len = len(np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/y_test.npy'))\n","val_len = len(np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/y_val.npy'))\n","\n","\n","def preprocess(file_name:str):\n","  local_vec_path = f\"/content/dataset/{PROCESS_VERSION}/{file_name}_{NUMBER_OF_INSTRUCTIONS}_{int(MAX_OPCODE_LENGHT/8)}.npy\"\n","  if not path.exists(local_vec_path):\n","    print('Preprossed data not found')\n","    exit(1)  \n","  else:\n","    output = np.load(local_vec_path)\n","  return output\n","\n","def load_presplitt(name:str):\n","  ids = np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/x_{name}.npy', allow_pickle=True)\n","  labels = np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/y_{name}.npy', allow_pickle=True)\n","  return ids, labels\n","\n","class Data_Generator(Sequence):\n","  def __init__(self, batch_size, folder):\n","    image_filenames, labels = load_presplitt(folder)\n","    self.image_filenames = image_filenames\n","    self.labels = labels\n","    self.batch_size = batch_size\n","    self.folder = folder\n","  \n","  def __len__(self) :\n","    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(int)\n","\n","  def __getitem__(self, idx) :\n","    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n","    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n","    return np.array([preprocess(file_name) for file_name in batch_x]).reshape(-1,3200, 8, 1), np.array(batch_y)\n","\n","train_generator = Data_Generator(BATCH_SIZE, 'train')\n","val_generator = Data_Generator(BATCH_SIZE, 'val')\n","test_generator = Data_Generator(BATCH_SIZE, 'test')"]},{"cell_type":"markdown","metadata":{"id":"CX4fRf2Cv-wm"},"source":["## Define Logger"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yzr5EnlgwHZF"},"outputs":[],"source":["environ['MLFLOW_TRACKING_USERNAME'] = MLFLOW_TRACKING_USERNAME\n","environ['MLFLOW_TRACKING_PASSWORD'] = MLFLOW_TRACKING_PASSWORD\n","environ['MLFLOW_TRACKING_URI'] = MLFLOW_TRACKING_URI\n","environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n","environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n","environ[\"MLFLOW_S3_ENDPOINT_URL\"] = MLFLOW_S3_ENDPOINT_URL\n","mlflow.set_experiment(Model_Name)\n","mlflow.start_run()\n","mlflow.log_artifact(local_path = '/content/drive/MyDrive/QMUL/Dissertation/src/notebooks/Assembly_Input_Model.ipynb')\n","\n","mlflow.log_param('class_weight',class_weight)\n","mlflow.log_param('epochs',EPOCHS)\n","mlflow.log_param('batch_size',BATCH_SIZE)\n","mlflow.log_param('opt_learning_rate',LEARNING_RATE)\n","mlflow.log_param('Eager Execution',True)\n","mlflow.log_param('opt_name','adam')\n","mlflow.log_param('steps_per_epoch',int(train_len // BATCH_SIZE))\n","mlflow.log_param('validation_steps',int(val_len // BATCH_SIZE))\n","mlflow.log_param('dataset',DATASET)\n","mlflow.log_param('preprocess version',PROCESS_VERSION)\n","mlflow.log_param('dropout',DROPOUT)\n","mlflow.log_param('K',K)\n","\n","def CheckpointCallback():\n","    return ModelCheckpoint(filepath=\"/content/Checkpoint\",verbose=1,save_weights_only=False,save_best_only=True)\n","\n","class CustomCallback(Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        mlflow.log_metrics(logs,epoch)"]},{"cell_type":"markdown","metadata":{"id":"b-3MSM-KvhAb"},"source":["## Model Definition"]},{"cell_type":"markdown","metadata":{"id":"4Qh0t18UyKbo"},"source":["### Architecture Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dq4cRg9pvu8I"},"outputs":[],"source":["def channel(input, kernel_size, name=''):\n","  x = Conv1D(filters=1, kernel_size=kernel_size, activation='relu', name=f\"Channel_{name}Conv1D\", padding=\"same\", strides=2)(input)\n","  x = BatchNormalization(name=f\"Channel_{name}_BatchNormalization\")(x)\n","  x = Activation(tanh)(x)\n","  x = MaxPooling2D(pool_size=(2,1), name=f\"Channel_{name}_MaxPooling2D\")(x)\n","  return x\n","\n","def Vector_Model():\n","  input = Input(shape=(NUMBER_OF_INSTRUCTIONS,int(MAX_OPCODE_LENGHT/8),1))\n","  channel_transformer = Conv2D(filters = K, kernel_size = 4, activation='relu', name='Channel_Transformer')(input)\n","\n","\t# channels\n","  channel1 = channel(input = channel_transformer, name = '1', kernel_size = 2)\n","  channel2 = channel(input = channel_transformer, name = '2', kernel_size = 3)\n","  channel3 = channel(input = channel_transformer, name = '3', kernel_size = 4)\n","  channel4 = channel(input = channel_transformer, name = '4', kernel_size = 5)\n"," \n","\t# channel merge\n","  merged = concatenate([channel1, channel2, channel3, channel4])\n","\n","\t# interpretation\n","  maxpoollayer = MaxPooling2D(pool_size=(4,1), name='MaxPool2D_Layer')(merged)\n","  dropout = Dropout(DROPOUT, name='Dropout_Layer')(maxpoollayer)\n","  flatten = Flatten(name='Flatten_Layer')(dropout)\n","  dense = Dense(18, activation='relu', name=\"Fully_Connected_Layer\")(flatten)\n","  output = Dense(9, activation='softmax' , name=\"Output_Layer\")(dense)\n","  model = Model(inputs=input, outputs=output, name=\"MalVecNet\")\n","\n","  optimiser = Adam(learning_rate=LEARNING_RATE)\n","\n","\t# compile\n","  model.compile(loss='categorical_crossentropy', optimizer=optimiser, metrics=['accuracy','Recall','Precision'])\n","\n","  #return\n","  return model\n","model = Vector_Model()"]},{"cell_type":"markdown","metadata":{"id":"WWK0mu46Kw6L"},"source":["### Model Summary and Plot"]},{"cell_type":"code","source":["with open('model_summary.txt','w') as f:\n","    model.summary(print_fn=lambda x: f.write(x + '\\n'),show_trainable=True)\n","mlflow.log_artifact(local_path = '/content/model_summary.txt')\n","plot_model(model, show_shapes=True, to_file=f'/content/Model_Plot.png')\n","mlflow.log_artifact(local_path = '/content/Model_Plot.png')"],"metadata":{"id":"wUYUrM4lgHAa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rpognCskvntC"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-31rcVZvvQ4"},"outputs":[],"source":["history = model.fit(train_generator, epochs = EPOCHS, verbose = 1, validation_data = val_generator, steps_per_epoch = int(train_len // BATCH_SIZE),validation_steps = int(val_len // BATCH_SIZE), callbacks = [CheckpointCallback(), CustomCallback()], class_weight=class_weight)"]},{"cell_type":"markdown","metadata":{"id":"8m3RjyDivpaI"},"source":["## Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ZNz83upwzUf"},"outputs":[],"source":["from mlflow.models.signature import infer_signature\n","import pandas as pd\n","model.load_weights('/content/Checkpoint')\n","train = train_generator.__getitem__(0)[0]\n","predictions = model.predict(train)\n","mlflow.keras.log_model(model,artifact_path='model',signature=infer_signature(train, predictions), registered_model_name='MalVecNet')\n","score = model.evaluate(test_generator,verbose=1)\n","print(f'Test Accuracy: {score[1]*100}%, Test Recall: {score[2]*100}%, Test Precision: {score[3]*100}%')\n","mlflow.log_metrics({\"test_loss\": score[0], \"test_accuracy\": score[1], \"test_recall\": score[2], \"test_precision\": score[3]},(EPOCHS-1))\n","\n","def plot_confusion_matrix(model,test_generator):\n","    \"\"\"\n","    It takes a model, a test set, and a test label set, and plots a confusion matrix\n","    \n","    :param model: the model you want to plot the confusion matrix for\n","    :param x_test: the test data\n","    :param y_test: the test labels\n","    \"\"\"\n","    title = f'Model: {Model_Name}'\n","    labels = ['Ramnit', 'Lollipop', 'Kelihos_ver3', 'Vundo', 'Simda', 'Tracur', 'Kelihos_ver1', 'Obfuscator.ACY', 'Gatak']\n","    pred = model.predict(test_generator)\n","    \n","    df = pd.DataFrame(index = np.asarray(test_generator.image_filenames).transpose())\n","    df['pred_label'] = np.argmax(pred, axis=1).transpose()\n","    df['true_label'] = np.argmax(test_generator.labels, axis=1).transpose()\n","    df['correct'] = df.apply(lambda row: 1 if row.pred_label == row.true_label else 0, axis=1)\n","\n","    df.to_csv('/content/predictions.csv')\n","    mlflow.log_artifact(local_path = '/content/predictions.csv')\n","\n","    confusion_matrix_ = confusion_matrix(np.argmax(test_generator.labels, axis=1),np.argmax(pred, axis=1),normalize='true')\n","    confusionMatrixDisplay = ConfusionMatrixDisplay(confusion_matrix_, display_labels=labels)\n","    fig, ax = plt.subplots(figsize=(20,20))\n","    label_font = {'size':'18'}\n","    plt.rcParams.update({'font.size': 14})\n","    ax.set_xlabel('Predicted labels', fontdict=label_font)\n","    ax.set_ylabel('Observed labels', fontdict=label_font)\n","    ax.set_title('Confusion Matrix '+title, fontdict={'size':'22'})\n","    ax.tick_params(axis='both', which='major', labelsize=14)\n","    cmD= confusionMatrixDisplay.plot(ax=ax,cmap = plt.get_cmap('Blues'), xticks_rotation='vertical')\n","    mlflow.log_figure(cmD.figure_, \"confusion_matrix.png\")\n","\n","plot_confusion_matrix(model,test_generator)\n","mlflow.end_run()"]}]}