{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ensemble.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","private_outputs":true,"mount_file_id":"1oZD2gbjbnjrKqeKtrmedOmjN4FIzmcSN","authorship_tag":"ABX9TyPsQvNlUsilvB5QkE8+1u7z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Ensemble"],"metadata":{"id":"L9w3yVOU5Rle"}},{"cell_type":"markdown","source":["### Introduction\n","This ensemble model combines the following three replication of models:\n","* MalVecNet from Jiang et al. 2019 [1]\n","* BitNet from Lin and Yeh 2022 [2]\n","* VisNet from Pinhero et al. 2021 [3]\n","\n","In the paper, the model is trained an tested on the Microsoft BIG 2015 **[4]** dataset and achives a accuracy of 98.7%.\n","\n","1. The MalVecNet mode has been adjusted as follows:\n","  - Instead of using a Channel Transformer as described in the original paper, a convolution layer was used. The kernel was then set to 4, which corresponds to the logic of assembly language.\n","\n","2. BitNet has not been modified.\n","\n","3. VisNet was replicated, but due to misssing parameters achived a lower accuracy then reported in the original paper. \n","\n","### Results\n","The results from this model can be seen in the table.\n","\n","|Metric|with Auxiliary Outputs|without Auxiliary Outputs\n","|---|---|---|\n","|Accuracy|98.7%|98.4%|\n","|Precision|96.8%|98.6%|\n","|Recall|96.7%|98.4%|\n","\n","### Bibliography\n","**[1]** Y. Jiang, S. Li, Y. Wu, and F. Zou, ‘A Novel Image-Based Malware Classification Model Using Deep Learning’, in Neural Information Processing, vol. 11954, T. Gedeon, K. W. Wong, and M. Lee, Eds. Cham: Springer International Pub, 2019, pp. 150–161. doi: 10.1007/978-3-030-36711-4_14. <br>\n","**[2]** W.-C. Lin and Y.-R. Yeh, ‘Efficient Malware Classification by Binary Sequences with One-Dimensional Convolutional Neural Networks’, Mathematics, vol. 10, no. 4, p. 608, Feb. 2022, doi: 10.3390/math10040608. <br>\n","**[3]** A. Pinhero et al., ‘Malware detection employed by visualization and deep neural network’, Computers & Security, vol. 105, p. 102247, Jun. 2021, doi: 10.1016/j.cose.2021.102247.<br>\n","**[4]** R. Ronen, M. Radu, C. Feuerstein, E. Yom-Tov, and M. Ahmadi, ‘Microsoft Malware Classification Challenge’. arXiv, Feb. 22, 2018. Accessed: May 26, 2022. [Online]. Available: http://arxiv.org/abs/1802.10135"],"metadata":{"id":"Ee1OAff15QOG"}},{"cell_type":"code","source":["!pip install -q mlflow\n","!pip install -q folium==0.2.1\n","!pip install -q botocore\n","!pip install -q boto3\n","!pip install -q urllib3==1.25.9\n","\n","# Imports for Models\n","from keras.utils.vis_utils import plot_model\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, Lambda, Flatten, BatchNormalization, Activation, LeakyReLU, Add\n","from keras.layers.convolutional import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D\n","from keras.activations import tanh\n","from keras.layers.merge import concatenate\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import Sequence\n","from keras.regularizers import l1_l2\n","\n","# Import for MLflow\n","import mlflow.tensorflow\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from mlflow.models.signature import infer_signature\n","from os import environ\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","from keras.callbacks import Callback\n","\n","# Params for MLflow\n","MLFLOW_TRACKING_URI = ''\n","MLFLOW_S3_ENDPOINT_URL = ''\n","AWS_ACCESS_KEY_ID = \"minio\"\n","AWS_SECRET_ACCESS_KEY = \"SN2FbaVcHCBAqr\"\n","MLFLOW_TRACKING_USERNAME = 'admin'\n","MLFLOW_TRACKING_PASSWORD = 'DPBgs7Z8XQcNAp'\n","\n","# Imports for data\n","import numpy as np\n","import pandas as pd\n","from os import makedirs\n","from os import path\n","\n","# Hyperparameters\n","BATCH_SIZE = 30\n","EPOCHS = 60\n","LEARNING_RATE = 0.00015\n","MalVecNet_LEARNING_RATE = int(0.0001*(BATCH_SIZE/15)) # learning rate has been adjusted to fit the batch size\n","BitNet_LEARNING_RATE = int(0.0001*(BATCH_SIZE/40)) # learning rate has been adjusted to fit the batch size\n","VisNet_LEARNING_RATE = int(0.000007*(BATCH_SIZE/200)) # learning rate has been adjusted to fit the batch size\n","sub_models_trainable = False\n","load_pretrained_models = True\n","DATASET = 'raw'\n","\n","all_traiable_after_epoch = 30\n","\n","Model_Name = 'Ensemble_with_AUX'\n","\n","\n","GDRIVE_LOCATION='MyDrive/git/Malware_Classification_Ensemble'"],"metadata":{"id":"PDs1xQe39tbt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Individual Models"],"metadata":{"id":"DmGYmwplKj4T"}},{"cell_type":"markdown","source":["## Load Dataset from Google Drive"],"metadata":{"id":"CUgowHM19lhM"}},{"cell_type":"code","source":["# create local directories to save the preprocessed datasets\n","if not path.exists(f'/content/dataset/1d/'):\n","  makedirs(f'/content/dataset/1d/')\n","  makedirs(f'/content/dataset/vector/')\n","  makedirs(f'/content/dataset/2d/')\n","\n","# copy the individual datasets\n","%cp -R -n /content/drive/{GDRIVE_LOCATION}/data/BitNet/1/. /content/dataset/1d/\n","%cp -R -n /content/drive/{GDRIVE_LOCATION}/data/MalVecNet/3/. /content/dataset/vector/\n","%cp -R -n /content/drive/{GDRIVE_LOCATION}/data/VisNet/6/. /content/dataset/2d/\n","\n","# calculate the class_weights based on the train set\n","y_train_data = np.load(f'/content/drive/{GDRIVE_LOCATION}/data/splits/{DATASET}/y_train.npy')\n","df = pd.DataFrame(np.argmax(y_train_data,axis=1), columns=['lables'])\n","F1, F2, F3, F4, F5, F6, F7, F8, F9 = [(1/len(x)) for _, x in df.groupby(df['lables'])]\n","class_weight = {0:F1, 1:F2, 2: F3, 3:F4, 4:F5, 5:F6, 6:F7, 7:F8, 8:F9}\n","\n","# get the length of each set so that it can be used for step calculation during the training\n","train_len = len(y_train_data)\n","test_len = len(np.load(f'/content/drive/{GDRIVE_LOCATION}/data/splits/{DATASET}/y_test.npy'))\n","val_len = len(np.load(f'/content/drive/{GDRIVE_LOCATION}/data/splits/{DATASET}/y_val.npy'))"],"metadata":{"id":"tLmnM0iaRxgS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download the saved model weights from Google Drive\n","%cp -R -n /content/drive/{GDRIVE_LOCATION}/models/.weights/. /content/"],"metadata":{"id":"l5nA_E1s4Zz4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## BitNet"],"metadata":{"id":"mpGjvsrEJP1G"}},{"cell_type":"code","source":["# the bitnet model from run 2e7f4fe682834ef2bf7b82fd8acac45b\n","BitNet_Version = 25\n","def Vector_Model():\n","  input = Input(shape=(18432,1))\n","  Conv_layer_1 = Conv1D(filters = 16, kernel_size = 8, activation=LeakyReLU(alpha=0.01), name='Conv_layer_1', strides = 8)(input)\n","  Conv_layer_2 = Conv1D(filters = 16, kernel_size = 3, activation=LeakyReLU(alpha=0.01), name='Conv_layer_2', strides = 1, padding = 'same')(Conv_layer_1)\n","  maxpoollayer_1 = MaxPooling1D(pool_size=2, name='maxpoollayer_1')(Conv_layer_2)\n","  Conv_layer_3 = Conv1D(filters = 32, kernel_size = 3, activation=LeakyReLU(alpha=0.01), name='Conv_layer_3', strides = 2, padding = 'same')(maxpoollayer_1)\n","  maxpoollayer_2 = MaxPooling1D(pool_size=2, name='maxpoollayer_2')(Conv_layer_3)\n","  Conv_layer_4 = Conv1D(filters = 64, kernel_size = 3, activation=LeakyReLU(alpha=0.01), name='Conv_layer_4', strides = 2, padding = 'same')(maxpoollayer_2)\n","  maxpoollayer_3 = MaxPooling1D(pool_size=2, name='maxpoollayer_3')(Conv_layer_4)\n","  Conv_layer_5 = Conv1D(filters = 128, kernel_size = 3, activation=LeakyReLU(alpha=0.01), name='Conv_layer_5', strides = 2, padding= 'same')(maxpoollayer_3)\n","  maxpoollayer_4 = MaxPooling1D(pool_size=2, name='maxpoollayer_4')(Conv_layer_5)\n","  Conv_layer_6 = Conv1D(filters = 128, kernel_size = 3, activation=LeakyReLU(alpha=0.01), name='Conv_layer_6', strides = 2, padding= 'same')(maxpoollayer_4)\n","  Conv_layer_7 = Conv1D(filters = 128, kernel_size = 3, activation=LeakyReLU(alpha=0.01), name='Conv_layer_7', strides = 2, padding= 'same')(Conv_layer_6)\n","  flatten = Flatten(name='BN_Flatten_Layer')(Conv_layer_7)\n","  dropout = Dropout(0.6)(flatten)\n","  FC_layer_1 = Dense(512, activation=LeakyReLU(alpha=0.01), name=\"FC_layer_1\")(dropout)\n","  output = Dense(9, activation='softmax' , name=\"BN_Output_Layer\")(FC_layer_1)\n","  model = Model(inputs=input, outputs=output)\n","  model.compile(loss='categorical_crossentropy', optimizer = Adam(learning_rate = BitNet_LEARNING_RATE), metrics=['accuracy','Recall','Precision'], run_eagerly=True)\n","  return model\n","bitnet = Vector_Model()\n","if load_pretrained_models:\n","  bitnet.load_weights('/content/BitNet')\n","bitnet.trainable = sub_models_trainable"],"metadata":{"id":"YeAG1bLbJPPf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## MalVecNet"],"metadata":{"id":"dyBzRc_zJSCC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tY1eeS_VJHkM"},"outputs":[],"source":["# the malvecnet model from run a650c36dfffd43dc8dcd9c4802886890\n","MalVecNet_Version = 3\n","def channel(input, kernel_size, name=''):\n","  x = Conv1D(filters=1, kernel_size=kernel_size, activation='relu', name=f\"Channel_{name}Conv1D\", padding=\"same\", strides=2)(input)\n","  x = BatchNormalization(name=f\"Channel_{name}_BatchNormalization\")(x)\n","  x = Activation(tanh)(x)\n","  x = MaxPooling2D(pool_size=(2,1), name=f\"Channel_{name}_MaxPooling2D\")(x)\n","  return x\n","\n","def Vector_Model():\n","  input = Input(shape=(3200,int(64/8),1))\n","  channel_transformer = Conv2D(filters = 5, kernel_size = 4, activation='relu', name='Channel_Transformer')(input)\n","\n","\t# channels\n","  channel1 = channel(input = channel_transformer, name = '1', kernel_size = 2)\n","  channel2 = channel(input = channel_transformer, name = '2', kernel_size = 3)\n","  channel3 = channel(input = channel_transformer, name = '3', kernel_size = 4)\n","  channel4 = channel(input = channel_transformer, name = '4', kernel_size = 5)\n"," \n","\t# channel merge\n","  merged = concatenate([channel1, channel2, channel3, channel4])\n","\n","\t# interpretation\n","  maxpoollayer = MaxPooling2D(pool_size=(4,1), name='MaxPool2D_Layer')(merged)\n","  dropout = Dropout(0.3, name='Dropout_Layer')(maxpoollayer)\n","  flatten = Flatten(name='MVN_Flatten_Layer')(dropout)\n","  dense = Dense(18, activation='relu', name=\"Fully_Connected_Layer\")(flatten)\n","  output = Dense(9, activation='softmax' , name=\"MVN_Output_Layer\")(dense)\n","  model = Model(inputs=input, outputs=output)\n","\t# compile\n","  model.compile(loss='categorical_crossentropy', optimizer = Adam(learning_rate = MalVecNet_LEARNING_RATE), metrics=['accuracy','Recall','Precision'], run_eagerly=True)\n","\n","  #return\n","  return model\n","malvecnet = Vector_Model()\n","if load_pretrained_models:\n","  malvecnet.load_weights('/content/MalVecNet')\n","malvecnet.trainable = sub_models_trainable"]},{"cell_type":"markdown","source":["## VisNet"],"metadata":{"id":"Ek2po_Qu3T5I"}},{"cell_type":"code","source":["# the Visnet model from run f6173accd84642d48114e3342447ffba\n","VisNet_Version = 36\n","def DNN():\n","  WEIGHT_DECAY_L1 =  0.0000001\n","  WEIGHT_DECAY_L2 =  0.0000001\n","  input = Input(shape=(1282))\n","  x = Dense(1282, activation = None, kernel_regularizer=l1_l2(l1 = WEIGHT_DECAY_L1, l2 = WEIGHT_DECAY_L2))(input)\n","  x = BatchNormalization()(x)\n","  x = Dropout(0.2)(x)\n","  x = Dense(1024, activation = None, kernel_regularizer=l1_l2(l1 = WEIGHT_DECAY_L1, l2 = WEIGHT_DECAY_L2))(x)\n","  x = Dense(1024, activation = None, kernel_regularizer=l1_l2(l1 = WEIGHT_DECAY_L1, l2 = WEIGHT_DECAY_L2))(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(0.2)(x)\n","  x = Dense(1024, activation = None, kernel_regularizer=l1_l2(l1 = WEIGHT_DECAY_L1, l2 = WEIGHT_DECAY_L2))(x)\n","  x = Dense(1024, activation = None, kernel_regularizer=l1_l2(l1 = WEIGHT_DECAY_L1, l2 = WEIGHT_DECAY_L2))(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(0.2)(x)\n","  x = Dense(1024, activation = None, kernel_regularizer=l1_l2(l1 = WEIGHT_DECAY_L1, l2 = WEIGHT_DECAY_L2))(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(0.2)(x)\n","  output = Dense(9, activation='softmax' , name=\"Vis_Output_Layer\")(x)\n","  model = Model(inputs=input, outputs=output, name=\"Entropy_Model\")\n","  model.compile(loss='categorical_crossentropy', optimizer = Adam(learning_rate = VisNet_LEARNING_RATE), metrics=['accuracy','Recall','Precision'], run_eagerly=True)\n","  return model\n","visnet = DNN()\n","if load_pretrained_models:\n","  visnet.load_weights('/content/VisNet')\n","visnet.trainable = sub_models_trainable"],"metadata":{"id":"W4ENMk2c3V7O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Ensemble Model"],"metadata":{"id":"iDsuZDT-Kns0"}},{"cell_type":"markdown","source":["### MLFlow"],"metadata":{"id":"Gy9jRnspEeRS"}},{"cell_type":"code","source":["environ['MLFLOW_TRACKING_USERNAME'] = MLFLOW_TRACKING_USERNAME\n","environ['MLFLOW_TRACKING_PASSWORD'] = MLFLOW_TRACKING_PASSWORD\n","environ['MLFLOW_TRACKING_URI'] = MLFLOW_TRACKING_URI\n","environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n","environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n","environ[\"MLFLOW_S3_ENDPOINT_URL\"] = MLFLOW_S3_ENDPOINT_URL\n","mlflow.set_experiment(Model_Name)\n","mlflow.start_run()\n","mlflow.log_artifact(local_path = f'/content/drive/{GDRIVE_LOCATION}/notebooks/Ensemble.ipynb')\n","mlflow.log_param('class_weight',class_weight)\n","mlflow.log_param('epochs',EPOCHS)\n","mlflow.log_param('batch_size',BATCH_SIZE)\n","mlflow.log_param('opt_learning_rate',LEARNING_RATE)\n","mlflow.log_param('opt_name','adam')\n","mlflow.log_param('steps_per_epoch',int(train_len // BATCH_SIZE))\n","mlflow.log_param('validation_steps',int(val_len // BATCH_SIZE))\n","mlflow.log_param('BitNet_Version',BitNet_Version)\n","mlflow.log_param('MalVecNet_Version',MalVecNet_Version)\n","mlflow.log_param('VisNet_Version',VisNet_Version)\n","mlflow.log_param('sub_models_trainable',sub_models_trainable)\n","mlflow.log_param('BitNet_load_pretrained',load_pretrained_models)\n","mlflow.log_param('dataset',DATASET)\n","if sub_models_trainable or all_traiable_after_epoch>=0:\n","  mlflow.log_param('BitNet_opt_learning_rate',BitNet_LEARNING_RATE)\n","  mlflow.log_param('MalVecNet_opt_learning_rate',MalVecNet_LEARNING_RATE)\n","  mlflow.log_param('VisNet_opt_learning_rate',VisNet_LEARNING_RATE)\n","\n","def CheckpointCallback():\n","    return ModelCheckpoint(filepath=\"/content/Checkpoint\",verbose=1,save_weights_only=False,save_best_only=True)\n","\n","class CustomCallback(Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        mlflow.log_metrics(logs,epoch)"],"metadata":{"id":"O5HSZIPnEhOd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data Generator for Ensemble Model"],"metadata":{"id":"rISFbZQN-K2U"}},{"cell_type":"code","source":["# the data will not be preprocessed in this script but relies on the preprossed data, that has been created for the training of the individual models\n","\n","def preprocess_bitnet(file_name:str):\n","  local_prosseced_path = f\"/content/dataset/1d/{file_name}.npy\"\n","  output = np.load(local_prosseced_path)\n","  return output\n","\n","def preprocess_malvecnet(file_name:str):\n","  local_vec_path = f\"/content/dataset/vector/{file_name}_{3200}_{int(64/8)}.npy\"\n","  output = np.load(local_vec_path)\n","  return output\n","\n","def preprocess_visnet(file_name:str):\n","  local_prosseced_path = f\"/content/dataset/2d/{file_name}.npy\"\n","  output = np.load(local_prosseced_path)\n","  return output\n","\n","def load_presplitt(name:str):\n","  ids = np.load(f'/content/drive/{GDRIVE_LOCATION}/data/splits/{DATASET}/x_{name}.npy', allow_pickle=True)\n","  labels = np.load(f'/content/drive/{GDRIVE_LOCATION}/data/splits/{DATASET}/y_{name}.npy', allow_pickle=True)\n","  return ids, labels\n","\n","class Data_Generator(Sequence):\n","  def __init__(self, batch_size, folder):\n","    image_filenames, labels = load_presplitt(folder)\n","    self.image_filenames = image_filenames\n","    self.labels = labels\n","    self.batch_size = batch_size\n","    self.folder = folder\n","\n","  def __len__(self):\n","    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(int)\n","\n","  def __getitem__(self, idx):\n","    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n","    y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n","    x = [np.asarray([preprocess_bitnet(file_name) for file_name in batch_x]).reshape(-1,18432,1), np.asarray([preprocess_malvecnet(file_name) for file_name in batch_x]).reshape(-1,3200, 8,1), np.array([np.asarray(preprocess_visnet(file_name),dtype='float64') for file_name in batch_x]).reshape(-1,1282)]\n","    return x, [y,y,y,y]\n","\n","train_generator = Data_Generator(BATCH_SIZE, 'train')\n","val_generator = Data_Generator(BATCH_SIZE, 'val')\n","test_generator = Data_Generator(BATCH_SIZE, 'test')"],"metadata":{"id":"HeYET-jYYczm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_full = concatenate([bitnet.output, malvecnet.output, visnet.output])\n","hidden_full = Dense(27, activation='ReLU' , name=\"Full_Hidden_Layer\")(merged_full)\n","dense_full = Dense(9, activation='softmax' , name=\"Full_Output_Layer\")(hidden_full)\n","\n","merged_left = concatenate([bitnet.output, malvecnet.output])\n","hidden_left = Dense(18, activation='ReLU' , name=\"Left_Hidden_Layer\")(merged_left)\n","dense_left = Dense(9, activation='softmax' , name=\"Left_Output_Layer\")(hidden_left)\n","\n","merged_right = concatenate([malvecnet.output, visnet.output])\n","hidden_right = Dense(18, activation='ReLU' , name=\"Right_Hidden_Layer\")(merged_right)\n","dense_right = Dense(9, activation='softmax' , name=\"Right_Output_Layer\")(hidden_right)\n","\n","add_left_right = Add()([dense_left,dense_right])\n","addition = Add()([bitnet.output, malvecnet.output, visnet.output])\n","merged_left_right_add = concatenate([add_left_right, addition, dense_full])\n","final_hidden = Dense(27, activation='ReLU' , name=\"Final_Hidden_Layer\")(merged_left_right_add)\n","output = Dense(9, activation='softmax' , name=\"Final_Output_Layer\")(final_hidden)\n","\n","losses_weight = { \"Final_Output_Layer\": 1.0, \"BN_Output_Layer\": 0.2, \"MVN_Output_Layer\": 0.2, \"Vis_Output_Layer\": 0.2}\n","\n","model = Model(inputs=[bitnet.input, malvecnet.input, visnet.input],outputs=[output,bitnet.output, malvecnet.output, visnet.output], name='Ensemble')\n","model.compile(loss='categorical_crossentropy', loss_weights = losses_weight, optimizer=Adam(learning_rate=LEARNING_RATE), metrics=['accuracy','Recall','Precision'], run_eagerly=True)"],"metadata":{"id":"DAeRvCUcKrUl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('model_summary.txt','w') as f:\n","    model.summary(print_fn=lambda x: f.write(x + '\\n'),show_trainable=True)\n","mlflow.log_artifact(local_path = '/content/model_summary.txt')\n","plot_model(model, show_shapes=True, to_file=f'/content/Model_Plot.png')"],"metadata":{"id":"REKsvdYwFhk1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mlflow.log_artifact(local_path = '/content/Model_Plot.png')"],"metadata":{"id":"KNOoXGqqFkgW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if all_traiable_after_epoch==-1:\n","  model.fit(train_generator, epochs = EPOCHS, verbose = 1, validation_data = val_generator, steps_per_epoch = int(train_len // BATCH_SIZE),validation_steps = int(val_len // BATCH_SIZE), class_weight=class_weight, callbacks = [CheckpointCallback(), CustomCallback()])\n","if all_traiable_after_epoch>=0:\n","  model.fit(train_generator, epochs = all_traiable_after_epoch, verbose = 1, validation_data = val_generator, steps_per_epoch = int(train_len // BATCH_SIZE),validation_steps = int(val_len // BATCH_SIZE), callbacks = [CheckpointCallback(), CustomCallback()])\n","  mlflow.log_param('all_traiable_after_epoch',all_traiable_after_epoch)\n","  malvecnet.trainable = True\n","  bitnet.trainable = True\n","  visnet.trainable = True\n","  bitnet.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate = BitNet_LEARNING_RATE), metrics=['accuracy','Recall','Precision'], run_eagerly=True)\n","  malvecnet.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate = MalVecNet_LEARNING_RATE), metrics=['accuracy','Recall','Precision'], run_eagerly=True)\n","  model.compile(loss='categorical_crossentropy', optimizer = Adam(learning_rate = VisNet_LEARNING_RATE), metrics=['accuracy','Recall','Precision'], run_eagerly=True)\n","  model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=LEARNING_RATE), metrics=['accuracy','Recall','Precision'], run_eagerly=True)\n","  with open(f'model_summary_post_epoch{all_traiable_after_epoch}.txt','w') as f:\n","    model.summary(print_fn=lambda x: f.write(x + '\\n'),show_trainable=True)\n","  mlflow.log_artifact(local_path = f'/content/model_summary_post_epoch{all_traiable_after_epoch}.txt')\n","  model.load_weights('/content/Checkpoint')\n","  model.fit(train_generator, epochs = EPOCHS, initial_epoch = all_traiable_after_epoch, verbose = 1, validation_data = val_generator, steps_per_epoch = int(train_len // BATCH_SIZE),validation_steps = int(val_len // BATCH_SIZE), callbacks = [CheckpointCallback(), CustomCallback()])"],"metadata":{"id":"PFKS4z-qUFgO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_weights('/content/Checkpoint')\n","train = train_generator.__getitem__(0)[0]\n","predictions = model.predict(train)\n","input = {'BitNet Input':train[0],'MalVecNet Input':train[1], 'VisNet Input':train[2]}\n","mlflow.keras.log_model(model,artifact_path='model',signature=infer_signature(input, predictions[0]), registered_model_name = Model_Name)\n","score = model.evaluate(test_generator,verbose=1)\n","print(f'Test Loss: {score[0]}, Test Accuracy: {score[5]*100}%, Test Recall: {score[9]*100}%, Test Precision: {score[13]*100}%')\n","mlflow.log_metrics({\"test_loss\": score[0], \"test_accuracy\": score[5], \"test_recall\": score[9], \"test_precision\": score[13]},(EPOCHS-1))\n","\n","def plot_confusion_matrix(model,test_generator):\n","    title = f'Model: {Model_Name}'\n","    labels = ['Ramnit', 'Lollipop', 'Kelihos_ver3', 'Vundo', 'Simda', 'Tracur', 'Kelihos_ver1', 'Obfuscator.ACY', 'Gatak']\n","    pred = model.predict(test_generator)\n","    \n","    df = pd.DataFrame(index = np.asarray(test_generator.image_filenames).transpose())\n","    df['pred_label'] = np.argmax(pred[0], axis=1).transpose()\n","    df['true_label'] = np.argmax(test_generator.labels, axis=1).transpose()\n","    df['correct'] = df.apply(lambda row: 1 if row.pred_label == row.true_label else 0, axis=1)\n","\n","    df.to_csv('/content/predictions.csv')\n","    mlflow.log_artifact(local_path = '/content/predictions.csv')\n","\n","    confusion_matrix_ = confusion_matrix(np.argmax(test_generator.labels, axis=1),np.argmax(pred[0], axis=1),normalize='true')\n","    confusionMatrixDisplay = ConfusionMatrixDisplay(confusion_matrix_, display_labels=labels)\n","    fig, ax = plt.subplots(figsize=(20,20))\n","    label_font = {'size':'18'}\n","    plt.rcParams.update({'font.size': 14})\n","    ax.set_xlabel('Predicted labels', fontdict=label_font)\n","    ax.set_ylabel('Observed labels', fontdict=label_font)\n","    ax.set_title('Confusion Matrix '+title, fontdict={'size':'22'})\n","    ax.tick_params(axis='both', which='major', labelsize=14)\n","    cmD= confusionMatrixDisplay.plot(ax=ax,cmap = plt.get_cmap('Blues'), xticks_rotation='vertical')\n","    mlflow.log_figure(cmD.figure_, \"confusion_matrix.png\")\n","\n","plot_confusion_matrix(model,test_generator)\n","mlflow.end_run()"],"metadata":{"id":"siVeYxZmZnvk"},"execution_count":null,"outputs":[]}]}