{"cells":[{"cell_type":"markdown","metadata":{"id":"tFXphBJJvG8g"},"source":["# Entropy Input Model"]},{"cell_type":"markdown","metadata":{"id":"u61hBZ9EwNFa"},"source":["### Introduction\n","This model is based on the paper from Pinhero et al. 2021 **[1]** . It uses Entropy information as input for a DNN to classify malware.\n","\n","In the paper, the model is trained an tested on the Microsoft BIG 2015 dataset and achives a accuracy of 98.25%.\n","\n","In this inplementaion, that model has been trained on the Microsoft BIG 2015 dataset (2018 revision) **[2]**.\n","\n","### Results\n","The best results from this model and the comparion to the original paper results can be seen in the table.\n","\n","|Metric|Repilicated Model|Original Model|\n","|---|---|---|\n","|Accuracy|87.7%|95.94%|\n","\n","\n","### Bibliography\n","**[1]** A. Pinhero et al., ‘Malware detection employed by visualization and deep neural network’, Computers & Security, vol. 105, p. 102247, Jun. 2021, doi: 10.1016/j.cose.2021.102247. <br>\n","**[2]** R. Ronen, M. Radu, C. Feuerstein, E. Yom-Tov, and M. Ahmadi, ‘Microsoft Malware Classification Challenge’. arXiv, Feb. 22, 2018. Accessed: May 26, 2022. [Online]. Available: http://arxiv.org/abs/1802.10135 <br>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e8pFuuujA3Aj"},"outputs":[],"source":["!pip install -q mlflow\n","!pip install -q folium==0.2.1\n","!pip install -q botocore\n","!pip install -q boto3\n","!pip install -q urllib3==1.25.9\n","\n","from keras.backend import dtype\n","from tensorflow.keras.utils import Sequence\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from keras.regularizers import l1_l2\n","\n","import mlflow.tensorflow\n","import scipy.interpolate as interp\n","from os import environ\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.metrics import confusion_matrix\n","from keras.utils.vis_utils import plot_model\n","from keras.callbacks import Callback\n","\n","import numpy as np\n","import pandas as pd\n","from os import path\n","from os import makedirs\n","\n","# Params for MLflow\n","MLFLOW_TRACKING_URI = ''\n","MLFLOW_S3_ENDPOINT_URL = ''\n","AWS_ACCESS_KEY_ID = \"minio\"\n","AWS_SECRET_ACCESS_KEY = \"SN2FbaVcHCBAqr\"\n","MLFLOW_TRACKING_USERNAME = 'admin'\n","MLFLOW_TRACKING_PASSWORD = 'DPBgs7Z8XQcNAp'\n","\n","Model_Name = 'VisNet'"]},{"cell_type":"markdown","metadata":{"id":"s7u65w09yPHY"},"source":["## Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yk-D6FrxySDH"},"outputs":[],"source":["#@title Set hyperparameters:\n","\n","#@markdown In the original paper 30 epochs have been used.\n","EPOCHS = 400 #@param \n","\n","#@markdown The original paper uses a learning rate of 0.0001.\n","LEARNING_RATE = 0.000007 #@param {type:\"number\"}\n","\n","#@markdown The orignal paper used a bacth size of 64.\n","BATCH_SIZE =  200#@param \n","\n","#@markdown Whithin the paper, the dataset has not augumented. The replication equally does not augument the dataset.\n","DATASET = \"raw\" #@param [\"raw\", \"YongImage\", \"Upsampled\"]\n","\n","WEIGHT_DECAY_L1 =  0.0000001#@param\n","WEIGHT_DECAY_L2 =  0.0000001#@param\n","\n","DROPOUT = 0.2 #@param"]},{"cell_type":"markdown","metadata":{"id":"PciYW2oYvZME"},"source":["## Data Loading and Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7fe96ExvuDg"},"outputs":[],"source":["PROCESS_VERSION = 6\n","\n","if not path.exists(f'/content/dataset/{PROCESS_VERSION}/'):\n","  makedirs(f'/content/dataset/{PROCESS_VERSION}/')\n","\n","%cp -R -n /content/drive/MyDrive/QMUL/Dissertation/dataset/processed/2d/{PROCESS_VERSION}/. /content/dataset/{PROCESS_VERSION}/\n","\n","y_train_data = np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/y_train.npy')\n","df = pd.DataFrame(np.argmax(y_train_data,axis=1), columns=['lables'])\n","F1, F2, F3, F4, F5, F6, F7, F8, F9 = [(1/len(x)) for _, x in df.groupby(df['lables'])]\n","class_weight = {0:F1, 1:F2, 2: F3, 3:F4, 4:F5, 5:F6, 6:F7, 7:F8, 8:F9}\n","train_len = len(y_train_data)\n","test_len = len(np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/y_test.npy'))\n","val_len = len(np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/y_val.npy'))\n","\n","def preprocess(file_name:str):\n","  local_prosseced_path = f\"/content/dataset/{PROCESS_VERSION}/{file_name}.npy\"\n","  if not path.exists(local_prosseced_path):\n","    print('Preprossed data not found')\n","    exit(1)  \n","  else:\n","    output = np.load(local_prosseced_path)\n","  return output\n","\n","def load_presplitt(name:str):\n","  ids = np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/x_{name}.npy', allow_pickle=True)\n","  labels = np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/y_{name}.npy', allow_pickle=True)\n","  return ids, labels\n","\n","class Data_Generator(Sequence):\n","  def __init__(self, batch_size, folder):\n","    image_filenames, labels = load_presplitt(folder)\n","    self.image_filenames = image_filenames\n","    self.labels = labels\n","    self.batch_size = batch_size\n","    self.folder = folder\n","  \n","  def __len__(self) :\n","    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(int)\n","\n","  def __getitem__(self, idx) :\n","    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n","    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n","    return np.array([np.asarray(preprocess(file_name),dtype='float64') for file_name in batch_x]).reshape(-1,1282), np.array(batch_y)\n","\n","train_generator = Data_Generator(BATCH_SIZE, 'train')\n","val_generator = Data_Generator(BATCH_SIZE, 'val')\n","test_generator = Data_Generator(BATCH_SIZE, 'test')"]},{"cell_type":"markdown","metadata":{"id":"CX4fRf2Cv-wm"},"source":["## Define Logger"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dq4cRg9pvu8I"},"outputs":[],"source":["environ['MLFLOW_TRACKING_USERNAME'] = MLFLOW_TRACKING_USERNAME\n","environ['MLFLOW_TRACKING_PASSWORD'] = MLFLOW_TRACKING_PASSWORD\n","environ['MLFLOW_TRACKING_URI'] = MLFLOW_TRACKING_URI\n","environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n","environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n","environ[\"MLFLOW_S3_ENDPOINT_URL\"] = MLFLOW_S3_ENDPOINT_URL\n","mlflow.set_experiment(Model_Name)\n","mlflow.start_run()\n","mlflow.log_artifact(local_path = '/content/drive/MyDrive/QMUL/Dissertation/src/notebooks/Entropy_Input_Model.ipynb')\n","\n","mlflow.log_param('dataset',DATASET)\n","mlflow.log_param('preprocess version',PROCESS_VERSION)\n","mlflow.log_param('Eager Execution',True)\n","mlflow.log_param('class_weight',class_weight)\n","mlflow.log_param('epochs',EPOCHS)\n","mlflow.log_param('batch_size',BATCH_SIZE)\n","mlflow.log_param('opt_learning_rate',LEARNING_RATE)\n","mlflow.log_param('opt_name','Adam')\n","#mlflow.log_param('opt_momentum', 0.9)\n","mlflow.log_param('steps_per_epoch',int(train_len // BATCH_SIZE))\n","mlflow.log_param('validation_steps',int(val_len // BATCH_SIZE))\n","mlflow.log_param('weight_decay_L1',WEIGHT_DECAY_L1)\n","mlflow.log_param('weight_decay_L2',WEIGHT_DECAY_L2)\n","mlflow.log_param('dropout',DROPOUT)\n","\n","def CheckpointCallback():\n","    return ModelCheckpoint(filepath=\"/content/Checkpoint\",verbose=1,save_weights_only=False,save_best_only=True)\n","\n","class CustomCallback(Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        mlflow.log_metrics(logs,epoch)"]},{"cell_type":"markdown","metadata":{"id":"b-3MSM-KvhAb"},"source":["## Model Definition"]},{"cell_type":"markdown","metadata":{"id":"4Qh0t18UyKbo"},"source":["### Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yzr5EnlgwHZF"},"outputs":[],"source":["def DNN():\n","  input = Input(shape=(1282))\n","  x = Dense(1282, activation = None, kernel_regularizer=l1_l2(l1 = WEIGHT_DECAY_L1, l2 = WEIGHT_DECAY_L2))(input)\n","  x = BatchNormalization()(x)\n","  x = Dropout(DROPOUT)(x)\n","  x = Dense(1024, activation = None, kernel_regularizer=l1_l2(l1 = WEIGHT_DECAY_L1, l2 = WEIGHT_DECAY_L2))(x)\n","  x = Dense(1024, activation = None, kernel_regularizer=l1_l2(l1 = WEIGHT_DECAY_L1, l2 = WEIGHT_DECAY_L2))(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(DROPOUT)(x)\n","  x = Dense(1024, activation = None, kernel_regularizer=l1_l2(l1 = WEIGHT_DECAY_L1, l2 = WEIGHT_DECAY_L2))(x)\n","  x = Dense(1024, activation = None, kernel_regularizer=l1_l2(l1 = WEIGHT_DECAY_L1, l2 = WEIGHT_DECAY_L2))(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(DROPOUT)(x)\n","  x = Dense(1024, activation = None, kernel_regularizer=l1_l2(l1 = WEIGHT_DECAY_L1, l2 = WEIGHT_DECAY_L2))(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(DROPOUT)(x)\n","  output = Dense(9, activation='softmax' , name=\"Output_Layer\")(x)\n","  model = Model(inputs=input, outputs=output, name=\"Entropy_Model\")\n","  optimiser = Adam(learning_rate=LEARNING_RATE)\n","  model.compile(loss='categorical_crossentropy', optimizer=optimiser, metrics=['accuracy','Recall','Precision'])\n","  return model\n","model = DNN()"]},{"cell_type":"markdown","metadata":{"id":"WWK0mu46Kw6L"},"source":["### Model Summary and Plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wUYUrM4lgHAa"},"outputs":[],"source":["with open('model_summary.txt','w') as f:\n","    model.summary(print_fn=lambda x: f.write(x + '\\n'),show_trainable=True)\n","mlflow.log_artifact(local_path = '/content/model_summary.txt')\n","plot_model(model, show_shapes=True, to_file=f'/content/Model_Plot.png')\n","mlflow.log_artifact(local_path = '/content/Model_Plot.png')"]},{"cell_type":"markdown","metadata":{"id":"rpognCskvntC"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-31rcVZvvQ4"},"outputs":[],"source":["history = model.fit(train_generator, epochs = EPOCHS, verbose = 1, validation_data = val_generator, steps_per_epoch = int(train_len // BATCH_SIZE),validation_steps = int(val_len // BATCH_SIZE), callbacks = [CheckpointCallback(), CustomCallback()], class_weight=class_weight)"]},{"cell_type":"markdown","metadata":{"id":"8m3RjyDivpaI"},"source":["## Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ZNz83upwzUf"},"outputs":[],"source":["from mlflow.models.signature import infer_signature\n","import pandas as pd\n","model.load_weights('/content/Checkpoint')\n","train = train_generator.__getitem__(0)[0]\n","predictions = model.predict(train)\n","mlflow.keras.log_model(model,artifact_path='model',signature=infer_signature(train, predictions), registered_model_name=Model_Name)\n","score = model.evaluate(test_generator,verbose=1)\n","print(f'Test Accuracy: {score[1]*100}%, Test Recall: {score[2]*100}%, Test Precision: {score[3]*100}%')\n","mlflow.log_metrics({\"test_loss\": score[0], \"test_accuracy\": score[1], \"test_recall\": score[2], \"test_precision\": score[3]},(EPOCHS-1))\n","\n","def plot_confusion_matrix(model,test_generator):\n","    \"\"\"\n","    It takes a model, a test set, and a test label set, and plots a confusion matrix\n","    \n","    :param model: the model you want to plot the confusion matrix for\n","    :param x_test: the test data\n","    :param y_test: the test labels\n","    \"\"\"\n","    title = f'Model: {Model_Name}'\n","    labels = ['Ramnit', 'Lollipop', 'Kelihos_ver3', 'Vundo', 'Simda', 'Tracur', 'Kelihos_ver1', 'Obfuscator.ACY', 'Gatak']\n","    pred = model.predict(test_generator)\n","    \n","    df = pd.DataFrame(index = np.asarray(test_generator.image_filenames).transpose())\n","    df['pred_label'] = np.argmax(pred, axis=1).transpose()\n","    df['true_label'] = np.argmax(test_generator.labels, axis=1).transpose()\n","    df['correct'] = df.apply(lambda row: 1 if row.pred_label == row.true_label else 0, axis=1)\n","\n","    df.to_csv('/content/predictions.csv')\n","    mlflow.log_artifact(local_path = '/content/predictions.csv')\n","\n","    confusion_matrix_ = confusion_matrix(np.argmax(test_generator.labels, axis=1),np.argmax(pred, axis=1),normalize='true')\n","    confusionMatrixDisplay = ConfusionMatrixDisplay(confusion_matrix_, display_labels=labels)\n","    fig, ax = plt.subplots(figsize=(20,20))\n","    label_font = {'size':'18'}\n","    plt.rcParams.update({'font.size': 14})\n","    ax.set_xlabel('Predicted labels', fontdict=label_font)\n","    ax.set_ylabel('Observed labels', fontdict=label_font)\n","    ax.set_title('Confusion Matrix '+title, fontdict={'size':'22'})\n","    ax.tick_params(axis='both', which='major', labelsize=14)\n","    cmD= confusionMatrixDisplay.plot(ax=ax,cmap = plt.get_cmap('Blues'), xticks_rotation='vertical')\n","    mlflow.log_figure(cmD.figure_, \"confusion_matrix.png\")\n","\n","plot_confusion_matrix(model,test_generator)\n","mlflow.end_run()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Entropy_Input_Model.ipynb","provenance":[],"mount_file_id":"1msRjA-PAup9wsJUyYkdJxEUlpOxfK4mm","authorship_tag":"ABX9TyNCbA75mbK4re/f08874Lfd"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}