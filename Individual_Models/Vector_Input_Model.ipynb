{"cells":[{"cell_type":"markdown","metadata":{"id":"tFXphBJJvG8g"},"source":["# Vector Input Model"]},{"cell_type":"markdown","metadata":{"id":"u61hBZ9EwNFa"},"source":["### Introduction\n","This model is based on the paper fron Jian et al. 2019 **[1]**. It uses a word vector representation of the malware as input and a CNN network for classification.\n","\n","In the paper, the model is trained an tested on the Microsoft BIG 2015 **[2]** dataset and achives a accuracy of 99.49%.\n","\n","In this inplementaion, that model has been trained on the Microsoft BIG 2015 dataset (2018 revision).\n","\n","The original paper does not directly mention model paramters such as filter size, but refers to a previous paper by Kim 2014 **[3]**. These paramters have therefore been extraced from this paper.\n","\n","### Results\n","The best results from this model and the comparion to the original paper results can be seen in the table.\n","\n","|Metric|Repilicated Model|Original Model|\n","|---|---|---|\n","|Accuracy||99.49%|\n","|Precision||99.51%|\n","|Recall||99.51%|\n","\n","### Bibliography\n","**[1]** Y. Jiang, S. Li, Y. Wu, and F. Zou, ‘A Novel Image-Based Malware Classification Model Using Deep Learning’, in Neural Information Processing, vol. 11954, T. Gedeon, K. W. Wong, and M. Lee, Eds. Cham: Springer International Pub, 2019, pp. 150–161. doi: 10.1007/978-3-030-36711-4_14. <br>\n","**[2]** R. Ronen, M. Radu, C. Feuerstein, E. Yom-Tov, and M. Ahmadi, ‘Microsoft Malware Classification Challenge’. arXiv, Feb. 22, 2018. Accessed: May 26, 2022. [Online]. Available: http://arxiv.org/abs/1802.10135\n","<br>\n","**[3]** Y. Kim, ‘Convolutional Neural Networks for Sentence Classification’, in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Doha, Qatar, Oct. 2014, pp. 1746–1751. doi: 10.3115/v1/D14-1181.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"s7u65w09yPHY"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yk-D6FrxySDH"},"outputs":[],"source":["#@title Set hyperparameters:\n","\n","#@markdown The orignal paper does not mention how many epochs have been used for training. In this implementation it was found that [...] epochs lead to the best results \n","EPOCHS = 400 #@param {type:\"slider\", min:0, max:1000, step:20}\n","\n","#@markdown The orignal paper not mention the  learning rate used. In this implementation it was found that a learning rate of [...] lead to the best results\n","LEARNING_RATE =  0.0001#@param {type:\"number\"}\n","\n","#@markdown The orignal paper does not mention the Batch_size used. In this implementation it was found that a batch size of [...] lead to the best results\n","BATCH_SIZE = 40 #@param {type:\"slider\", min:1, max:100, step:1}\n","\n","#@markdown The orignal paper find that K 1 results in the best results. In this implementation it was found that a K of [...] lead to the best results\n","K = 5 #@param {type:\"slider\", min:1, max: 8, step:1}\n","\n","#@markdown The orignal paper set the max opcode size to 64, but does not experiment with different lenghts. In this implementation it was found that a K of [...] lead to the best results\n","MAX_OPCODE_LENGHT = 64 #@param {type:\"slider\", min:32, max: 256, step:32}\n","\n","#@markdown The paper does not clarifiy which dropout has been used after the final maxpooling. In this implementation, it has been found that [...] leads to the best resutls.\n","DROPOUT = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.1}\n","\n","#@markdown Within the original paper, this parameter is called m as defined as 3200.\n","NUMBER_OF_INSTRUCTIONS = 3200 #@param {type:\"slider\", min:0, max:6400, step:200}\n","\n","#@markdown Whithin the paper, the dataset has been augumented. One can train the model with the augmented dataset or the pure dataset.\n","DATASET = \"YongImage\" #@param [\"pure\", \"YongImage\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CueKj3hbi-ZN"},"outputs":[],"source":["GIT_COMMIT_HASH = ''"]},{"cell_type":"markdown","metadata":{"id":"PciYW2oYvZME"},"source":["## Data Loading and Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7fe96ExvuDg"},"outputs":[],"source":["from tensorflow.keras.utils import Sequence\n","import numpy as np\n","import re\n","from pyparsing import Word, hexnums, WordEnd, Optional, alphas, alphanums, printables, ParseException\n","import pandas as pd\n","\n","%cp -R -n /content/drive/MyDrive/QMUL/Dissertation/dataset/processed/vector/. /content/dataset/\n","y_train_data = np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/y_train.npy')\n","df = pd.DataFrame(np.argmax(y_train_data,axis=1), columns=['lables'])\n","F1, F2, F3, F4, F5, F6, F7, F8, F9 = [(1/len(x)) for _, x in df.groupby(df['lables'])]\n","class_weight = {0:F1, 1:F2, 2: F3, 3:F4, 4:F5, 5:F6, 6:F7, 7:F8, 8:F9}\n","train_len = len(y_train_data)\n","test_len = len(np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/y_test.npy'))\n","val_len = len(np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/y_val.npy'))\n","\n","regex = re.compile(r'[\\n\\r\\t\\?\\;\\_\\'\\-]')\n","hex_integer = Word(hexnums) + WordEnd()\n","search = \".\" + Word(alphas,alphanums)('section') + \":\" + hex_integer('adress') + Optional((hex_integer*(1,))(\"instructions\") + Word(alphas,alphanums)(\"opcode\")) + Optional(Word(alphas,alphanums)('first_operant')) + Optional(\",\" + Word(printables)('second_operant'))\n","\n","PROCESS_VERSION = 2\n","\n","def pad(A, length):\n","    arr = np.zeros(length)\n","    arr[:len(A)] = A\n","    return arr\n","\n","def pad2D(A, height, width):\n","    c_height, c_width = A.shape\n","    return np.pad(A, ((0,(height-c_height)),(0,width-c_width)), 'constant')\n","\n","def asm_to_np(file):\n","    RESULT = []\n","    counter = 0\n","    counter_2 = 0\n","    for line in file.readlines():\n","            line = regex.sub(\" \", line)\n","            try:\n","                line = search.parseString(line)\n","                section = line.section.encode(encoding = 'ASCII', errors = 'ignore')\n","                adress = bytes.fromhex(''.join(line.adress.asList() if not line.adress == None else ''))\n","                opcode = line.opcode.encode(encoding = 'ASCII', errors = 'ignore') if not line.opcode == '' else ' '.encode(encoding = 'ASCII', errors = 'ignore')\n","                operants = f'{line.first_operant},{line.second_operant}'.encode(encoding = 'ASCII', errors = 'ignore')\n","                instructions = bytes.fromhex(''.join(line.instructions.asList() if not line.instructions == '' else ''))\n","                byteline = section[0].to_bytes(1, byteorder='big')+adress[2:]+instructions[:4]+opcode[0].to_bytes(1, byteorder='big')+operants\n","                np_array = np.frombuffer(byteline, dtype='uint8')\n","                np_array = pad(np_array[0:int(MAX_OPCODE_LENGHT/8)],int(MAX_OPCODE_LENGHT/8))\n","                RESULT.append(np_array)\n","                counter += 1\n","                if counter >= NUMBER_OF_INSTRUCTIONS: break \n","            except ParseException as e:\n","                continue\n","            except ValueError as e:\n","                continue\n","            counter_2 += 1\n","            if counter_2 >= 12000:\n","                break\n","    if len(RESULT)==0: RESULT = np.ones((3200,8))\n","    RESULT = pad2D(np.asarray(RESULT)[:NUMBER_OF_INSTRUCTIONS,:int(MAX_OPCODE_LENGHT/8)],NUMBER_OF_INSTRUCTIONS,int(MAX_OPCODE_LENGHT/8))\n","    return RESULT\n","\n","def preprocess(file_name:str):\n","  asm_path = f\"/content/drive/MyDrive/QMUL/Dissertation/dataset/train/{file_name}.asm\"\n","  vec_path = f\"/content/drive/MyDrive/QMUL/Dissertation/dataset/processed/vector/{PROCESS_VERSION}/{file_name}_{NUMBER_OF_INSTRUCTIONS}_{int(MAX_OPCODE_LENGHT/8)}.npy\"\n","  local_vec_path = f\"/content/dataset/{PROCESS_VERSION}/{file_name}_{NUMBER_OF_INSTRUCTIONS}_{int(MAX_OPCODE_LENGHT/8)}.npy\"\n","  if not path.exists(local_vec_path):\n","    f = open(asm_path, \"r\", encoding = 'unicode_escape', errors='ignore')\n","    output = asm_to_np(f)\n","    np.save(vec_path,output)\n","    np.save(local_vec_path,output)\n","  else:\n","    output = np.load(local_vec_path)\n","  return output\n","\n","def load_presplitt(name:str):\n","  ids = np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/x_{name}.npy', allow_pickle=True)\n","  labels = np.load(f'/content/drive/MyDrive/QMUL/Dissertation/dataset/splits/{DATASET}/y_{name}.npy', allow_pickle=True)\n","  return ids, labels\n","\n","class Data_Generator(Sequence):\n","  def __init__(self, batch_size, folder):\n","    image_filenames, labels = load_presplitt(folder)\n","    self.image_filenames = image_filenames\n","    self.labels = labels\n","    self.batch_size = batch_size\n","    self.folder = folder\n","  \n","  def __len__(self) :\n","    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(int)\n","\n","  def __getitem__(self, idx) :\n","    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n","    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n","    return np.array([preprocess(file_name) for file_name in batch_x]), np.array(batch_y)\n","\n","train_generator = Data_Generator(BATCH_SIZE, 'train')\n","val_generator = Data_Generator(BATCH_SIZE, 'val')\n","test_generator = Data_Generator(BATCH_SIZE, 'test')"]},{"cell_type":"markdown","metadata":{"id":"CX4fRf2Cv-wm"},"source":["## Define Logger"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yzr5EnlgwHZF"},"outputs":[],"source":["!pip install -q mlflow\n","import mlflow.tensorflow\n","import os.path\n","from os import path\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","def mkdir_if_not_exist(dir):\n","    try:\n","        if not path.exists(dir):\n","            print('Creating directory {} for the checkpoint'.format(dir))\n","            os.makedirs(dir)\n","    except: \n","        print('Could not check for existence of directory for the checkpoints. Please make sure that the directory exists')\n","\n","MLFLOW_DIR = \"/content/drive/MyDrive/QMUL/Dissertation/MLflow/Vector_Input_Model/\"\n","mkdir_if_not_exist(MLFLOW_DIR)\n","\n","%cd /content/drive/MyDrive/QMUL/Dissertation/MLflow/Vector_Input_Model/\n","mlflow.tensorflow.autolog(registered_model_name='Vector')\n","mlflow.set_experiment(\"Vector\")\n","\n","mlflow.log_param('dataset',DATASET)\n","mlflow.log_param('preprocess version',PROCESS_VERSION)\n","mlflow.log_param('dropout',DROPOUT)\n","mlflow.log_param('K',K)\n","\n","source_base_uri = f'{str(mlflow.get_artifact_uri(\"/\")[7:-10])}/tags/mlflow.source.'\n","fp = open(f'{source_base_uri}git.commit', 'w')\n","fp.write(GIT_COMMIT_HASH)\n","fp.close()\n","\n","def CheckpointCallback():\n","    return ModelCheckpoint(filepath=str(mlflow.get_artifact_uri(artifact_path=\"Checkpoint\"))[7:],verbose=1,save_weights_only=False,save_best_only=True)"]},{"cell_type":"markdown","metadata":{"id":"b-3MSM-KvhAb"},"source":["## Model Definition"]},{"cell_type":"markdown","metadata":{"id":"4Qh0t18UyKbo"},"source":["### Architecture Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dq4cRg9pvu8I"},"outputs":[],"source":["from keras.utils.vis_utils import plot_model\n","from keras.models import Model\n","from keras.layers import Input, Dense, Flatten, Dropout, Embedding, BatchNormalization\n","from keras.layers.convolutional import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D\n","from keras.layers.merge import concatenate\n","from tensorflow.keras.optimizers import Adam, Adamax, SGD\n","\n","def channel(input, kernel_size, name=''):\n","  x = Conv1D(filters=1, kernel_size=kernel_size, activation='relu', name=f\"Channel_{name}Conv1D\", padding=\"same\")(input)\n","  x = BatchNormalization(name=f\"Channel_{name}_BatchNormalization\")(x)\n","  x = MaxPooling2D(pool_size=4, name=f\"Channel_{name}_MaxPooling2D\")(x)\n","  return x\n","\n","def Vector_Model():\n","  input = Input(shape=(NUMBER_OF_INSTRUCTIONS,int(MAX_OPCODE_LENGHT/8),1))\n","  channel_transformer = Conv2D(filters = K, kernel_size = 4, activation='relu', name='Channel_Transformer')(input)\n","\n","\t# channels\n","  channel1 = channel(input = channel_transformer, name = '1', kernel_size = 2)\n","  channel2 = channel(input = channel_transformer, name = '2', kernel_size = 3)\n","  channel3 = channel(input = channel_transformer, name = '3', kernel_size = 4)\n","  channel4 = channel(input = channel_transformer, name = '4', kernel_size = 5)\n"," \n","\t# channel merge\n","  merged = concatenate([channel1, channel2, channel3, channel4])\n","\n","\t# interpretation\t\n","  dropout = Dropout(DROPOUT, name='Dropout_Layer')(merged)\n","  maxpoollayer = MaxPooling2D(pool_size=1, name='MaxPool2D_Layer')(dropout)\n","  flatten = Flatten(name='Flatten_Layer')(maxpoollayer)\n","  dense = Dense(18, activation='relu', name=\"Fully_Connected_Layer\")(flatten)\n","  output = Dense(9, activation='softmax' , name=\"Output_Layer\")(dense)\n","  model = Model(inputs=input, outputs=output, name=\"OpCodeVector_Model\")\n","\n","  optimiser = Adam(learning_rate=LEARNING_RATE)\n","  #optimiser = Adamax(learning_rate=LEARNING_RATE)\n","  #optimiser = SGD(learning_rate = LEARNING_RATE, momentum=0.9)\n","\n","\t# compile\n","  model.compile(loss='categorical_crossentropy', optimizer=optimiser, metrics=['accuracy'])\n","\n","  #return\n","  return model\n","model = Vector_Model()"]},{"cell_type":"markdown","metadata":{"id":"lCTXLOgVS91N"},"source":["### Model Summary and Plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mo3WgJqdTGhm"},"outputs":[],"source":["print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Xf3luw6I42y"},"outputs":[],"source":["plot_model(model, show_shapes=True, to_file=f'{str(mlflow.get_artifact_uri())[7:]}/Model_Plot.png')"]},{"cell_type":"markdown","metadata":{"id":"rpognCskvntC"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-31rcVZvvQ4"},"outputs":[],"source":["history = model.fit(train_generator, epochs = EPOCHS, verbose = 1, validation_data = val_generator, steps_per_epoch = int(train_len // BATCH_SIZE),validation_steps = int(val_len // BATCH_SIZE), callbacks = [CheckpointCallback()], class_weight=class_weight)"]},{"cell_type":"markdown","metadata":{"id":"8m3RjyDivpaI"},"source":["## Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"loFZgMjHvvvA"},"outputs":[],"source":["score = model.evaluate(test_generator,verbose=1)\n","mlflow.log_metrics({\"test_loss\": score[0], \"test_accuracy\": score[1]},(EPOCHS-1))"]},{"cell_type":"markdown","metadata":{"id":"LzjnysCZvrmh"},"source":["## Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5vuSxAFh1UBK"},"outputs":[],"source":["#model.load_weights(CHECKPOINT_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8n4S_9YztY8"},"outputs":[],"source":["from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","\n","def plot_confusion_matrix(model,test_generator):\n","    \"\"\"\n","    It takes a model, a test set, and a test label set, and plots a confusion matrix\n","    \n","    :param model: the model you want to plot the confusion matrix for\n","    :param x_test: the test data\n","    :param y_test: the test labels\n","    \"\"\"\n","    title = 'Model: Vector_Input Optimizer'\n","    labels = ['Ramnit', 'Lollipop', 'Kelihos_ver3', 'Vundo', 'Simda', 'Tracur', 'Kelihos_ver1', 'Obfuscator.ACY', 'Gatak']\n","    pred = model.predict(test_generator, batch_size=100)\n","    \n","    df = pd.DataFrame(index = np.asarray(test_generator.image_filenames).transpose())\n","    df['pred_label'] = np.argmax(pred, axis=1).transpose()\n","    df['true_label'] = np.argmax(test_generator.labels, axis=1).transpose()\n","    df['correct'] = df.apply(lambda row: 1 if row.pred_label == row.true_label else 0, axis=1)\n","\n","    df.to_csv(f'{str(mlflow.get_artifact_uri(artifact_path=\"/\"))[7:]}predictions.csv')\n","\n","    confusion_matrix_ = confusion_matrix(np.argmax(test_generator.labels, axis=1),np.argmax(pred, axis=1),normalize='true')\n","    confusionMatrixDisplay = ConfusionMatrixDisplay(confusion_matrix_, display_labels=labels)\n","    fig, ax = plt.subplots(figsize=(20,20))\n","    label_font = {'size':'18'}\n","    plt.rcParams.update({'font.size': 14})\n","    ax.set_xlabel('Predicted labels', fontdict=label_font)\n","    ax.set_ylabel('Observed labels', fontdict=label_font)\n","    ax.set_title('Confusion Matrix '+title, fontdict={'size':'22'})\n","    ax.tick_params(axis='both', which='major', labelsize=14)\n","    cmD= confusionMatrixDisplay.plot(ax=ax,cmap = plt.get_cmap('Blues'), xticks_rotation='vertical')\n","    mlflow.log_figure(cmD.figure_, \"confusion_matrix.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kg0G1FnLuYG9"},"outputs":[],"source":["print(\"Overall Accuracy:\", score[1]*100,'%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rGFSSRoK1Oo5"},"outputs":[],"source":["plot_confusion_matrix(model,test_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JyaK6LIpERk"},"outputs":[],"source":["mlflow.end_run()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Vector_Input_Model.ipynb","provenance":[],"mount_file_id":"14fI4jsVayYY0FYDs646T7ETzdMuOfg63","authorship_tag":"ABX9TyMADALstmFZ+powS3BAJkRb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}