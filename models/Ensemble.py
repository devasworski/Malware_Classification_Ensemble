from tensorflow.keras.callbacks import ModelCheckpoint
from keras.models import Model
from keras.utils.vis_utils import plot_model
from keras.models import Model
from keras.layers import Input, Dense, Add
from keras.layers.merge import concatenate
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix
from keras.utils.vis_utils import plot_model
from keras.callbacks import Callback
import numpy as np
import pandas as pd
from os import makedirs
from dotenv import load_dotenv
from DataGenerator import Ensemble_Generator, get_classweight
import mlflow
from mlflow.models.signature import infer_signature
from shutil import rmtree
from MalVecNet import MalVecNet_Model
from VisNet import VisNet_Model
from BitNet import BitNet_Model
from json import load as jload


# Params for MLflow
load_dotenv()

Model_Name = 'Ensemble.py'
BATCH_SIZE = 30
EPOCHS = 60
LEARNING_RATE = 0.00015
MalVecNet_LEARNING_RATE = int(0.0001*(BATCH_SIZE/15)) # learning rate has been adjusted to fit the batch size
BitNet_LEARNING_RATE = int(0.0001*(BATCH_SIZE/40)) # learning rate has been adjusted to fit the batch size
VisNet_LEARNING_RATE = int(0.000007*(BATCH_SIZE/200)) # learning rate has been adjusted to fit the batch size
sub_models_trainable = False
load_pretrained_models = True
DATASET = 'raw'
all_traiable_after_epoch = 30

makedirs('.Ensemble', exist_ok = True)

class_weight = get_classweight(DATASET)
train_generator = Ensemble_Generator(BATCH_SIZE, 'train', DATASET)
val_generator = Ensemble_Generator(BATCH_SIZE, 'val', DATASET)
test_generator = Ensemble_Generator(BATCH_SIZE, 'test', DATASET)

mlflow.set_experiment(Model_Name)
mlflow.start_run()
mlflow.log_artifact(local_path = 'Ensemble.py')

with open('weights/meta.json') as meta_file:
    meta = jload(meta_file)
    mlflow.log_param('BitNet_Version',meta['BitNet_Version'])
    mlflow.log_param('MalVecNet_Version',meta['MalVecNet_Version'])
    mlflow.log_param('VisNet_Version',meta['VisNet_Version'])

mlflow.log_param('class_weight',class_weight)
mlflow.log_param('epochs',EPOCHS)
mlflow.log_param('batch_size',BATCH_SIZE)
mlflow.log_param('opt_learning_rate',LEARNING_RATE)
mlflow.log_param('opt_name','adam')
mlflow.log_param('steps_per_epoch',int(train_generator.sample_size() // BATCH_SIZE))
mlflow.log_param('validation_steps',int(val_generator.sample_size() // BATCH_SIZE))
mlflow.log_param('sub_models_trainable',sub_models_trainable)
mlflow.log_param('BitNet_load_pretrained',load_pretrained_models)
mlflow.log_param('dataset',DATASET)
if sub_models_trainable or all_traiable_after_epoch>=0:
  mlflow.log_param('BitNet_opt_learning_rate',BitNet_LEARNING_RATE)
  mlflow.log_param('MalVecNet_opt_learning_rate',MalVecNet_LEARNING_RATE)
  mlflow.log_param('VisNet_opt_learning_rate',VisNet_LEARNING_RATE)

def CheckpointCallback():
    return ModelCheckpoint(filepath=".Ensemble/Checkpoint",verbose=1,save_weights_only=False,save_best_only=True)

class CustomCallback(Callback):
    def on_epoch_end(self, epoch, logs=None):
        mlflow.log_metrics(logs,epoch)

malvecnet = MalVecNet_Model()
bitnet = BitNet_Model()
visnet = VisNet_Model()
if load_pretrained_models:
    malvecnet.load_weights('weights/MalVecNet')
    bitnet.load_weights('weights/BitNet')
    visnet.load_weights('weights/VisNet')
malvecnet.trainable = sub_models_trainable
bitnet.trainable = sub_models_trainable
visnet.trainable = sub_models_trainable

def Ensemble_Model():
    merged_full = concatenate([bitnet.output, malvecnet.output, visnet.output])
    hidden_full = Dense(27, activation='ReLU' , name="Full_Hidden_Layer")(merged_full)
    dense_full = Dense(9, activation='softmax' , name="Full_Output_Layer")(hidden_full)

    merged_left = concatenate([bitnet.output, malvecnet.output])
    hidden_left = Dense(18, activation='ReLU' , name="Left_Hidden_Layer")(merged_left)
    dense_left = Dense(9, activation='softmax' , name="Left_Output_Layer")(hidden_left)

    merged_right = concatenate([malvecnet.output, visnet.output])
    hidden_right = Dense(18, activation='ReLU' , name="Right_Hidden_Layer")(merged_right)
    dense_right = Dense(9, activation='softmax' , name="Right_Output_Layer")(hidden_right)

    add_left_right = Add()([dense_left,dense_right])
    addition = Add()([bitnet.output, malvecnet.output, visnet.output])
    merged_left_right_add = concatenate([add_left_right, addition, dense_full])
    final_hidden = Dense(27, activation='ReLU' , name="Final_Hidden_Layer")(merged_left_right_add)
    output = Dense(9, activation='softmax' , name="Final_Output_Layer")(final_hidden)

    losses_weight = { "Final_Output_Layer": 1.0, "BN_Output_Layer": 0.2, "MVN_Output_Layer": 0.2, "Vis_Output_Layer": 0.2}

    model = Model(inputs=[bitnet.input, malvecnet.input, visnet.input],outputs=[output,bitnet.output, malvecnet.output, visnet.output], name='Ensemble')
    model.compile(loss='categorical_crossentropy', loss_weights = losses_weight, optimizer=Adam(learning_rate=LEARNING_RATE), metrics=['accuracy','Recall','Precision'], run_eagerly=True)
    return model

model = Ensemble_Model()

with open('.Ensemble/model_summary.txt','w') as f:
    model.summary(print_fn=lambda x: f.write(x + '\n'),show_trainable=True)
mlflow.log_artifact(local_path = '.Ensemble/model_summary.txt')
plot_model(model, show_shapes=True, to_file=f'.Ensemble/Model_Plot.png')
mlflow.log_artifact(local_path = '.Ensemble/Model_Plot.png')

history = model.fit(train_generator, epochs = EPOCHS, verbose = 0, validation_data = val_generator, steps_per_epoch = int(train_generator.sample_size()  // BATCH_SIZE),validation_steps = int(val_generator.sample_size() // BATCH_SIZE), callbacks = [CheckpointCallback(), CustomCallback()], class_weight=class_weight)
mlflow.log_artifact(local_path = '.Ensemble/Checkpoint', artifact_path='')

model.load_weights('.Ensemble/Checkpoint')
train = train_generator.__getitem__(0)[0]
predictions = model.predict(train)
mlflow.keras.log_model(model,artifact_path='model',signature=infer_signature(train, predictions), registered_model_name=Model_Name)
score = model.evaluate(test_generator,verbose=1)
mlflow.log_metrics({"test_loss": score[0], "test_accuracy": score[1], "test_recall": score[2], "test_precision": score[3]},(EPOCHS-1))
print(f'Test Loss: {score[0]}, Test Accuracy: {score[1]*100}%, Test Recall: {score[2]*100}%, Test Precision: {score[3]*100}%')

def plot_confusion_matrix(model,test_generator):
    title = Model_Name
    labels = ['Ramnit', 'Lollipop', 'Kelihos_ver3', 'Vundo', 'Simda', 'Tracur', 'Kelihos_ver1', 'Obfuscator.ACY', 'Gatak']
    pred = model.predict(test_generator)
    df = pd.DataFrame(index = np.asarray(test_generator.image_filenames).transpose())
    df['pred_label'] = np.argmax(pred, axis=1).transpose()
    df['true_label'] = np.argmax(test_generator.labels, axis=1).transpose()
    df['correct'] = df.apply(lambda row: 1 if row.pred_label == row.true_label else 0, axis=1)
    df.to_csv('.Ensemble/predictions.csv')
    mlflow.log_artifact(local_path = '.Ensemble/predictions.csv')
    confusion_matrix_ = confusion_matrix(np.argmax(test_generator.labels, axis=1),np.argmax(pred, axis=1),normalize='true')
    confusionMatrixDisplay = ConfusionMatrixDisplay(confusion_matrix_, display_labels=labels)
    fig, ax = plt.subplots(figsize=(20,20))
    label_font = {'size':'18'}
    plt.rcParams.update({'font.size': 14})
    ax.set_xlabel('Predicted labels', fontdict=label_font)
    ax.set_ylabel('Observed labels', fontdict=label_font)
    ax.set_title('Confusion Matrix '+title, fontdict={'size':'22'})
    ax.tick_params(axis='both', which='major', labelsize=14)
    cmD= confusionMatrixDisplay.plot(ax=ax,cmap = plt.get_cmap('Blues'), xticks_rotation='vertical')
    mlflow.log_figure(cmD.figure_, "confusion_matrix.png")

plot_confusion_matrix(model,test_generator)
mlflow.end_run()

rmtree('.Ensemble/')