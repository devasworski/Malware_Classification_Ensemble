from keras.models import Model
from keras.layers import Input, Dense, Add
from keras.layers.merge import concatenate
from tensorflow.keras.optimizers import Adam
from os import makedirs, environ
from dotenv import load_dotenv
import mlflow
from mlflow.models.signature import infer_signature
from shutil import rmtree
from MalVecNet import MalVecNet_Model
from VisNet import VisNet_Model
from BitNet import BitNet_Model
from json import load as jload
from utils import Callbacks, Plot
from utils.DataGenerator import Ensemble_Generator, get_classweight

Model_Name = 'Ensemble.py'
TEMP_FOLDER = '.Ensemble'
BATCH_SIZE = 30
EPOCHS = 60
LEARNING_RATE = 0.00015
MalVecNet_LEARNING_RATE = int(0.0001*(BATCH_SIZE/15)) # learning rate has been adjusted to fit the batch size
BitNet_LEARNING_RATE = int(0.0001*(BATCH_SIZE/40)) # learning rate has been adjusted to fit the batch size
VisNet_LEARNING_RATE = int(0.000007*(BATCH_SIZE/200)) # learning rate has been adjusted to fit the batch size
sub_models_trainable = False
load_pretrained_models = True
DATASET = 'raw'
all_traiable_after_epoch = 30
environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

def Ensemble_Model():
    """
    It takes the three models as input, loads their weights if needed, sets their trainability,
    concatenates their outputs, and then feeds them into a dense layer
    :return: The model is being returned.
    """
    malvecnet = MalVecNet_Model()
    bitnet = BitNet_Model()
    visnet = VisNet_Model()
    if load_pretrained_models:
        malvecnet.load_weights('.weights/MalVecNet/')
        bitnet.load_weights('.weights/BitNet/')
        visnet.load_weights('.weights/VisNet/')
    malvecnet.trainable = sub_models_trainable
    bitnet.trainable = sub_models_trainable
    visnet.trainable = sub_models_trainable

    merged_full = concatenate([bitnet.output, malvecnet.output, visnet.output])
    hidden_full = Dense(27, activation='ReLU' , name="Full_Hidden_Layer")(merged_full)
    dense_full = Dense(9, activation='softmax' , name="Full_Output_Layer")(hidden_full)

    merged_left = concatenate([bitnet.output, malvecnet.output])
    hidden_left = Dense(18, activation='ReLU' , name="Left_Hidden_Layer")(merged_left)
    dense_left = Dense(9, activation='softmax' , name="Left_Output_Layer")(hidden_left)

    merged_right = concatenate([malvecnet.output, visnet.output])
    hidden_right = Dense(18, activation='ReLU' , name="Right_Hidden_Layer")(merged_right)
    dense_right = Dense(9, activation='softmax' , name="Right_Output_Layer")(hidden_right)

    add_left_right = Add()([dense_left,dense_right])
    addition = Add()([bitnet.output, malvecnet.output, visnet.output])
    merged_left_right_add = concatenate([add_left_right, addition, dense_full])
    final_hidden = Dense(27, activation='ReLU' , name="Final_Hidden_Layer")(merged_left_right_add)
    output = Dense(9, activation='softmax' , name="model")(final_hidden)

    losses_weight = { "model": 1.0, "output_BitNet": 0.2, "output_MalVecNet": 0.2, "output_VisNet": 0.2}

    model = Model(inputs=[bitnet.input, malvecnet.input, visnet.input],outputs=[output,bitnet.output, malvecnet.output, visnet.output], name='Ensemble')
    model.compile(loss='categorical_crossentropy', loss_weights = losses_weight, optimizer=Adam(learning_rate=LEARNING_RATE), metrics=['accuracy','Recall','Precision'], run_eagerly=True)
    return model

def train():
    """
    It loads the dataset, creates the model, trains the model, logs the model, and saves the model
    """
    load_dotenv()
    makedirs(TEMP_FOLDER, exist_ok = True)

    class_weight = get_classweight(DATASET)
    train_generator = Ensemble_Generator(BATCH_SIZE, 'train', DATASET)
    val_generator = Ensemble_Generator(BATCH_SIZE, 'val', DATASET)
    test_generator = Ensemble_Generator(BATCH_SIZE, 'test', DATASET)

    mlflow.set_experiment(Model_Name)
    mlflow.start_run()
    mlflow.log_artifact(local_path = 'Ensemble.py')
    with open('.weights/meta.json') as meta_file:
        meta = jload(meta_file)
        mlflow.log_param('BitNet_Version',meta['BitNet_Version'])
        mlflow.log_param('MalVecNet_Version',meta['MalVecNet_Version'])
        mlflow.log_param('VisNet_Version',meta['VisNet_Version'])
    mlflow.log_param('class_weight',class_weight)
    mlflow.log_param('epochs',EPOCHS)
    mlflow.log_param('batch_size',BATCH_SIZE)
    mlflow.log_param('opt_learning_rate',LEARNING_RATE)
    mlflow.log_param('opt_name','adam')
    mlflow.log_param('steps_per_epoch',int(train_generator.sample_size() // BATCH_SIZE))
    mlflow.log_param('validation_steps',int(val_generator.sample_size() // BATCH_SIZE))
    mlflow.log_param('sub_models_trainable',sub_models_trainable)
    mlflow.log_param('BitNet_load_pretrained',load_pretrained_models)
    mlflow.log_param('dataset',DATASET)
    if sub_models_trainable or all_traiable_after_epoch>=0:
        mlflow.log_param('BitNet_opt_learning_rate',BitNet_LEARNING_RATE)
        mlflow.log_param('MalVecNet_opt_learning_rate',MalVecNet_LEARNING_RATE)
        mlflow.log_param('VisNet_opt_learning_rate',VisNet_LEARNING_RATE)

    model = Ensemble_Model()

    Plot.summary(model, TEMP_FOLDER)

    model.fit(train_generator, epochs = EPOCHS, verbose = 1, validation_data = val_generator, steps_per_epoch = int(train_generator.sample_size()  // BATCH_SIZE),validation_steps = int(val_generator.sample_size() // BATCH_SIZE), callbacks = [Callbacks.CheckpointCallback(TEMP_FOLDER), Callbacks.CustomCallback()])
    mlflow.log_artifact(local_path = f'{TEMP_FOLDER}/Checkpoint', artifact_path='')

    model.load_weights(f'{TEMP_FOLDER}/Checkpoint')
    train = train_generator.__getitem__(0)[0]
    predictions = model.predict(train)
    input = {'BitNet Input':train[0],'MalVecNet Input':train[1], 'VisNet Input':train[2]}
    mlflow.keras.log_model(model,artifact_path='model',signature=infer_signature(input, predictions[0]), registered_model_name = Model_Name)
    score = model.evaluate(test_generator,verbose=1)
    print(f'Test Loss: {score[0]}, Test Accuracy: {score[5]*100}%, Test Recall: {score[9]*100}%, Test Precision: {score[13]*100}%')
    mlflow.log_metrics({"test_loss": score[0], "test_accuracy": score[5], "test_recall": score[9], "test_precision": score[13]},(EPOCHS-1))

    Plot.plot_confusion_matrix_with_aux(model, test_generator, Model_Name, TEMP_FOLDER)
    mlflow.end_run()

    rmtree(f'{TEMP_FOLDER}/')

if __name__ == "__main__":
    train()