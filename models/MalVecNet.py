from keras.models import Model
from keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization, Activation
from keras.layers.convolutional import Conv1D, MaxPooling2D, Conv2D
from keras.layers.merge import concatenate
from keras.activations import tanh
from tensorflow.keras.optimizers import Adam
from os import makedirs
from dotenv import load_dotenv
from mlflow import log_artifact, set_experiment, start_run, log_param, log_metrics, end_run
from mlflow.keras import log_model
from mlflow.models.signature import infer_signature
from shutil import rmtree
from utils import Callbacks, Plot
from utils.DataGenerator import MalVecNet_Generator, get_classweight

Model_Name = 'MalVecNet.py'
TEMP_FOLDER = '.MalVecNet'
EPOCHS = 100 #@param {type:"slider", min:0, max:1000, step:10}
LEARNING_RATE =  0.0001#@param {type:"number"}
BATCH_SIZE = 40 #@param {type:"slider", min:1, max:100, step:1}
K = 5 #@param {type:"slider", min:1, max: 8, step:1}
MAX_OPCODE_LENGHT = 64 #@param {type:"slider", min:32, max: 256, step:32}
DROPOUT = 0.3 #@param {type:"slider", min:0, max:1, step:0.1}
NUMBER_OF_INSTRUCTIONS = 3200 #@param {type:"slider", min:0, max:6400, step:200}
DATASET = "Upsampled" #@param ["raw", "YongImage","Upsampled"]

def channel(input, kernel_size, name=''):
  """
  Defines the channel, that takes an input, applies a convolutional layer, batch normalization, activation, and max pooling
  
  :param input: the input layer
  :param kernel_size: The size of the convolutional kernel
  :param name: The name of the layer. This is used to define the scope of the layer
  :return: A tensor with the shape of (None, 1, 1, 1)
  """
  x = Conv1D(filters=1, kernel_size=kernel_size, activation='relu', name=f"Channel_{name}Conv1D", padding="same", strides=2)(input)
  x = BatchNormalization(name=f"Channel_{name}_BatchNormalization")(x)
  x = Activation(tanh)(x)
  x = MaxPooling2D(pool_size=(2,1), name=f"Channel_{name}_MaxPooling2D")(x)
  return x

def MalVecNet_Model():
    """
    The function defines the MalVecNet model.

    The model takes in a 2D tensor of shape (NUMBER_OF_INSTRUCTIONS,int(MAX_OPCODE_LENGHT/8),1) and
    returns a 2D tensor of shape (9,)
    
    :return: The MalVecNet model is being returned.
    """
    input = Input(shape=(NUMBER_OF_INSTRUCTIONS,int(MAX_OPCODE_LENGHT/8),1))
    channel_transformer = Conv2D(filters = K, kernel_size = 4, activation='relu', name='Channel_Transformer')(input)

    channel1 = channel(input = channel_transformer, name = '1', kernel_size = 2)
    channel2 = channel(input = channel_transformer, name = '2', kernel_size = 3)
    channel3 = channel(input = channel_transformer, name = '3', kernel_size = 4)
    channel4 = channel(input = channel_transformer, name = '4', kernel_size = 5)
  
    merged = concatenate([channel1, channel2, channel3, channel4])

    maxpoollayer = MaxPooling2D(pool_size=(4,1), name='MaxPool2D_Layer')(merged)
    dropout = Dropout(DROPOUT, name='Dropout_Layer')(maxpoollayer)
    flatten = Flatten(name='flatten_Layer')(dropout)
    dense = Dense(18, activation='relu', name="Fully_Connected_Layer")(flatten)
    output = Dense(9, activation='softmax' , name="output_MalVecNet")(dense)
    model = Model(inputs=input, outputs=output, name="MalVecNet")

    optimiser = Adam(learning_rate=LEARNING_RATE)
    model.compile(loss='categorical_crossentropy', optimizer=optimiser, metrics=['accuracy','Recall','Precision'])

    return model

def train(): 
  """
  > The function `train()` creates a directory called `.MalVecNet` as temp folder to store the model checkpoints,
  loads the dataset, creates the model, trains the model, logs the model, logs the metrics, and
  deletes the `.MalVecNet` directory
  """
  makedirs(TEMP_FOLDER, exist_ok = True)

  # Params for MLflow
  load_dotenv()

  class_weight = get_classweight(DATASET)
  train_generator = MalVecNet_Generator(BATCH_SIZE, 'train', DATASET)
  val_generator = MalVecNet_Generator(BATCH_SIZE, 'val', DATASET)
  test_generator = MalVecNet_Generator(BATCH_SIZE, 'test', DATASET)

  set_experiment(Model_Name)
  start_run()
  log_artifact(local_path = 'MalVecNet.py')
  log_param('dataset',DATASET)
  log_param('dropout',DROPOUT)
  log_param('class_weight',class_weight)
  log_param('epochs',EPOCHS)
  log_param('batch_size',BATCH_SIZE)
  log_param('opt_learning_rate',LEARNING_RATE)
  log_param('opt_name','adam')
  log_param('steps_per_epoch',int(train_generator.sample_size() // BATCH_SIZE))
  log_param('validation_steps',int(val_generator.sample_size() // BATCH_SIZE))
  log_param('K',K)

  model = MalVecNet_Model()

  Plot.summary(model, TEMP_FOLDER)

  model.fit(train_generator, epochs = EPOCHS, verbose = 1, validation_data = val_generator, steps_per_epoch = int(train_generator.sample_size()  // BATCH_SIZE),validation_steps = int(val_generator.sample_size() // BATCH_SIZE), callbacks = [Callbacks.CheckpointCallback(TEMP_FOLDER), Callbacks.CustomCallback()], class_weight=class_weight)
  log_artifact(local_path = f'{TEMP_FOLDER}/Checkpoint', artifact_path='')

  model.load_weights(f'{TEMP_FOLDER}/Checkpoint')
  train = train_generator.__getitem__(0)[0]
  predictions = model.predict(train)
  log_model(model,artifact_path='model',signature=infer_signature(train, predictions), registered_model_name=Model_Name)
  score = model.evaluate(test_generator,verbose=1)
  log_metrics({"test_loss": score[0], "test_accuracy": score[1], "test_recall": score[2], "test_precision": score[3]},(EPOCHS-1))
  print(f'Test Loss: {score[0]}, Test Accuracy: {score[1]*100}%, Test Recall: {score[2]*100}%, Test Precision: {score[3]*100}%')

  Plot.plot_confusion_matrix(model, test_generator, Model_Name, TEMP_FOLDER)
  end_run()
  rmtree(f'{TEMP_FOLDER}/')

if __name__ == "__main__":
    train()