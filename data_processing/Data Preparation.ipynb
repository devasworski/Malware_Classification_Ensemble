{"cells":[{"cell_type":"markdown","metadata":{"id":"9cUYfiUKqlg4"},"source":["# Prepare Train, Val & Test"]},{"cell_type":"markdown","metadata":{"id":"vdA6WOWW04HX"},"source":["go to the director where the dataset is located and create a folder for the data splits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3aRHFyaUtxRg"},"outputs":[],"source":["%cd /content/drive/MyDrive/QMUL/Dissertation/dataset\n","import os\n","if not os.path.exists(\"splits/\"):\n","  os.makedirs('splits')"]},{"cell_type":"markdown","metadata":{"id":"ULFxk5fNsoE1"},"source":["## Raw Dataset\n","\n","As the dataset is to big to be loaded into most environments, a DataGenerator structure has bee Build in Keras. This will load the dataset in batched. For this, three files have been created. Each file respectively specifies which samples belong to test, validation or train. The test samples will be taken from the train dataset, as the test dataset has no true lables.\n","\n","In this section, the train, val & test splitt will remain as it is. Not data augumentation other then the splitt will be performed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTpwG3BPsn2i"},"outputs":[],"source":["%cd /content/drive/MyDrive/QMUL/Dissertation/dataset\n","from tensorflow.keras.utils import to_categorical\n","import os\n","import shutil\n","import csv\n","import numpy as np\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","\n","\n","if not os.path.exists(\"raw/\"):\n","  os.makedirs('raw')\n","\n","samples = {}\n","with open('trainLabels.csv', mode='r') as infile:\n","  reader = csv.reader(infile)\n","  label_dict = dict((rows[0],rows[1]) for rows in reader)\n","\n","for subdir, dirs, files in os.walk('train'):\n","  for file in files:\n","    sample_id = file.replace(\".asm\", \"\").replace(\".bytes\", \"\")\n","    sample_lable = int(label_dict.get(sample_id,'0'))-1\n","    samples.update({sample_id:sample_lable})\n","ids = []\n","lables = []\n","for id, lable in samples.items():\n","  ids.append(id)\n","  lables.append(lable)\n","lables = to_categorical(lables, num_classes=9)\n","np.save('splits/raw/all_train_filenames.npy', ids)\n","np.save('splits/raw/all_train_labels.npy', lables)\n","\n","ids_shuffled, labels_shuffled = shuffle(ids, lables)\n","np.save('splits/raw/all_shuffled_train_filenames.npy', ids_shuffled)\n","np.save('splits/pure/all_shuffled_train_labels.npy', labels_shuffled)\n","\n","# as there are no lables for the test dataset, the train dataset will be used for creating the testing dataset\n","x_train, x_test, y_train, y_test = train_test_split(np.array(ids_shuffled), labels_shuffled, test_size=0.1, random_state=False, stratify=labels_shuffled)\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=False, stratify=y_train)\n","  \n","np.save('splits/raw/x_train.npy', x_train)  \n","np.save('splits/raw/y_train.npy', y_train)  \n","np.save('splits/raw/x_test.npy', x_test)  \n","np.save('splits/raw/y_test.npy', y_test)  \n","np.save('splits/raw/x_val.npy', x_val)  \n","np.save('splits/raw/y_val.npy', y_val)"]},{"cell_type":"markdown","metadata":{"id":"1O-fvU9Bv_VB"},"source":["## YongImage Dataset\n","\n","As the dataset is to big to be loaded into most environments, a DataGenerator structure has bee Build in Keras. This will load the dataset in batched. For this, three files have been created. Each file respectively specifies which samples belong to test, validation or train. The test samples will be taken from the train dataset, as the test dataset has no true lables.\n","\n","In this section, the train, val & test splitt will be prepared accordingly to the YongImage paper. **[1]** For this the classes F4, F5 & F7 will be randomly upsamples to 500. This causes data leakage, which has not been considered within the original paper.\n","\n","**[1]** Y. Jiang, S. Li, Y. Wu, and F. Zou, ‘A Novel Image-Based Malware Classification Model Using Deep Learning’, in Neural Information Processing, vol. 11954, T. Gedeon, K. W. Wong, and M. Lee, Eds. Cham: Springer International Pub, 2019, pp. 150–161. doi: 10.1007/978-3-030-36711-4_14.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1BHqw-YpScq-"},"outputs":[],"source":["%cd /content/drive/MyDrive/QMUL/Dissertation/dataset/splits\n","from tensorflow.keras.utils import to_categorical\n","import os\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.utils import resample\n","\n","if not os.path.exists(\"YongImage/\"):\n","  os.makedirs('YongImage')\n","\n","df = pd.DataFrame(np.load('raw/all_shuffled_train_filenames.npy'),columns=['id'])\n","df['lables'] = pd.DataFrame(np.argmax(np.load('raw/all_shuffled_train_labels.npy'),axis=1))\n","F1, F2, F3, F4, F5, F6, F7, F8, F9 = [x for _, x in df.groupby(df['lables'])]\n","F4 = resample(F4, replace=True, n_samples=500, random_state=42)\n","F5 = resample(F5, replace=True, n_samples=500, random_state=42)\n","F7 = resample(F7, replace=True, n_samples=500, random_state=42)\n","df = pd.concat([F1, F2, F3, F4, F5, F6, F7, F8, F9])\n","ids = df['id'].to_numpy()\n","lables = df['lables'].to_numpy()\n","lables = to_categorical(lables, num_classes=9)\n","\n","# as there are no lables for the test dataset, the train dataset will be used for creating the testing dataset\n","x_train, x_test, y_train, y_test = train_test_split(np.array(ids), lables, test_size=0.1, random_state=False, stratify=lables)\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=False, stratify=y_train)\n","\n","np.save('YongImage/x_train.npy', x_train)  \n","np.save('YongImage/y_train.npy', y_train)  \n","np.save('YongImage/x_test.npy', x_test)  \n","np.save('YongImage/y_test.npy', y_test)  \n","np.save('YongImage/x_val.npy', x_val)  \n","np.save('YongImage/y_val.npy', y_val)"]},{"cell_type":"markdown","metadata":{"id":"iaejmdfFgQ2N"},"source":["## Upsampled\n","\n","As the dataset is to big to be loaded into most environments, a DataGenerator structure has bee Build in Keras. This will load the dataset in batched. For this, three files have been created. Each file respectively specifies which samples belong to test, validation or train. The test samples will be taken from the train dataset, as the test dataset has no true lables.\n","\n","In this section, the train, val & test splitt will be prepared similar to the YongImage paper. **[1]** For this the classes F4, F5 & F7 will be randomly upsamples. In order to prevent data leaking, which has not been considered within the original paper, only the Train data will be upsampled to 400. \n","\n","**[1]** Y. Jiang, S. Li, Y. Wu, and F. Zou, ‘A Novel Image-Based Malware Classification Model Using Deep Learning’, in Neural Information Processing, vol. 11954, T. Gedeon, K. W. Wong, and M. Lee, Eds. Cham: Springer International Pub, 2019, pp. 150–161. doi: 10.1007/978-3-030-36711-4_14.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQ4BYN5_gQ2X"},"outputs":[],"source":["%cd /content/drive/MyDrive/QMUL/Dissertation/dataset/splits\n","from tensorflow.keras.utils import to_categorical\n","import os\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.utils import resample\n","\n","if not os.path.exists(\"Upsampled/\"):\n","  os.makedirs('Upsampled')\n","\n","ids = np.load('raw/all_shuffled_train_filenames.npy')\n","lables = np.load('raw/all_shuffled_train_labels.npy')\n","\n","# as there are no lables for the test dataset, the train dataset will be used for creating the testing dataset\n","x_train, x_test, y_train, y_test = train_test_split(np.array(ids), lables, test_size=0.1, random_state=False, stratify=lables)\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=False, stratify=y_train)\n","\n","df = pd.DataFrame(x_train,columns=['id'])\n","df['lables'] = pd.DataFrame(np.argmax(y_train,axis=1))\n","F1, F2, F3, F4, F5, F6, F7, F8, F9 = [x for _, x in df.groupby(df['lables'])]\n","F4 = resample(F4, replace=True, n_samples=500, random_state=42)\n","F5 = resample(F5, replace=True, n_samples=500, random_state=42)\n","F7 = resample(F7, replace=True, n_samples=500, random_state=42)\n","df = pd.concat([F1, F2, F3, F4, F5, F6, F7, F8, F9])\n","x_train = df['id'].to_numpy()\n","y_train = df['lables'].to_numpy()\n","y_train = to_categorical(y_train, num_classes=9)\n","\n","np.save('Upsampled/x_train.npy', x_train)  \n","np.save('Upsampled/y_train.npy', y_train)  \n","np.save('Upsampled/x_test.npy', x_test)  \n","np.save('Upsampled/y_test.npy', y_test)  \n","np.save('Upsampled/x_val.npy', x_val)  \n","np.save('Upsampled/y_val.npy', y_val)"]},{"cell_type":"markdown","metadata":{"id":"z8i3DMWzqhqy"},"source":["# Force to sync the files with Google Drive\n","\n","This will ensure, that all files have been synced with GoogleDrive, before we close the runtime."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zyIZZ0_9mgl8"},"outputs":[],"source":["from google.colab import drive\n","drive.flush_and_unmount()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Data Preparation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}